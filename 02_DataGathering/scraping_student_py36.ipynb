{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>August 2014 - This notebook was created by [Oriol Pujol Vila](http://www.maia.ub.es/~oriol). Source and license info are in the folder.</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data hunting and gathering\n",
    "\n",
    "<img style = \"border-radius:20px;\" src = \"http://unadocenade.com/wp-content/uploads/2012/09/cavalls-de-valltorta.jpg\">\n",
    "\n",
    "SOFTWARE REQUIREMENTS\n",
    "    \n",
    "    + mongoDB \n",
    "    + lxml #pip install lxml\n",
    "    + cssselector #pip install cssselect\n",
    "    + pyquery #pip install pyquery\n",
    "    + selenium #pip install selenium\n",
    "    + pymongo #pip install pymongo\n",
    "    \n",
    "NOT REQUIRED BUT USED FOR SOME EXAMPLES: \n",
    "\n",
    "    + VLC\n",
    "\n",
    "CONTENTS\n",
    "\n",
    "+ Introduction and warm-up project: A web crawler\n",
    " \n",
    "     + Introduction to MongoDB and PyMongo\n",
    "     + A whirlwind tour into regular expressions\n",
    "    \n",
    "+ Using the API\n",
    "\n",
    "    + Retrieving Twitter data\n",
    "\n",
    "+ Creating our own web API: Scraping\n",
    "\n",
    "    + Understanding HTML and CSS\n",
    "    + CSS selectors\n",
    "    + XPath selectors\n",
    "    + Scraping dynamic content with Selenium    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is the basis of this course. Although we usually find it in well structured formats such as a spreadsheet resulting from our last experiment, or the collection of company records in a classical relational database, with the advent of internet new information sources have to be taken into account. However, these new sources are home of unstructured data. In this lecture several methods for retrieving data and storing it are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first introduce the big picture guiding this lecture. Whenever we want to retrieve data from a web site we should ask first if the web site is providing a simple way for that purpose. Many large sites such as google, facebook, twitter, etc, provide a **Application Programming Interface (API)** that can make data hunting easier. However, most of web sites do not have this interface. Even more, an API may not provide the desired information. In those cases we have to use **scraping** techniques. This means dealing with the raw information as it is provided to the web browser and code our data finding methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"border-radius:20px;\" src=\"./files/big_picture.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start connecting to the net and checking out how to retrieve a basic page. We will start using `urllib.request` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x7f71f8032dd8>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "source = urlopen(\"http://www.google.com/\")\n",
    "print(source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x7f71f8032dd8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us check what is in\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hurray we got a socket. An all sockets behave like files, so let us go read() the \"file\"\n",
    "something = source.read().decode('latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"es\"><head><meta content=\"Google.es permite acceder a la información mundial en castellano, catalán, gallego, euskara e inglés.\" name=\"description\"><meta content=\"noodp\" name=\"robots\"><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"jBBjMw5yWe8dNPI6XeutIA==\">(function(){window.google={kEI:'syyvXaC_ArCOlwSH-ICoDw',kEXPI:'0,1353747,5662,731,223,510,1065,3152,378,206,1017,53,2134,10,299,414,271,67,48,48,94,25,324,274,35,579,65,16,50,99,317,4,1130631,1197706,329561,1294,12383,4855,32691,15248,867,28684,369,3314,5505,2442,5942,1119,2,579,727,2432,1361,4323,4967,774,2251,2820,1923,3122,6192,1719,1808,1976,2044,8909,1900,3397,2016,38,920,873,1217,2975,2736,3061,2,631,3240,8066,2884,20,317,1119,904,101,2024,1,369,2777,919,992,509,776,8,2796,813,72,82,601,11,14,667,612,2212,202,325,3,1252,840,324,194,793,345,1,278,48,8,48,157,663,3438,109,151,52,1137,2,2063,606,1839,184,595,1182,520,502,1445,747,429,44,299,710,93,328,1284,16,84,336,81,2426,2246,474,134,1205,729,19,1039,3094,133,773,908,640,524,7,728,592,523,925,126,1176,1160,369,490,1544,4,708,57,1843,3148,12,25,50,614,52,1100,110,845,532,4,498,582,584,456,517,312,213,110,268,799,280,1112,660,246,42,559,416,655,50,95,136,560,91,523,601,458,321,914,679,729,203,684,67,88,258,131,47,2,5,2,7,210,209,314,39,132,11,18,6,131,81,160,281,379,102,447,142,220,534,1411,139,265,345,364,5879209,12,1805882,4194573,233,15,2799629,189,60,1323,549,333,444,1,2,80,1,900,583,1,312,1,8,1,2,2551,1,748,141,59,736,563,1,3815,341,1,98,9,1,1,1,1,1,3,7,8,2,5,1,2,15,16,2,2,2,15,33,2,1,14,1,1,5,1,2795612,17949964,3220020',authuser:0,kscs:'c9c918f0_syyvXaC_ArCOlwSH-ICoDw',kGL:'ES',kBL:'cXSl'};google.sn='webhp';google.kHL='es';google.jsfs='Ffpdje';})();(function(){google.lc=[];google.li=0;google.getEI=function(a){for(var b;a&&(!a.getAttribute||!(b=a.getAttribute(\"eid\")));)a=a.parentNode;return b||google.kEI};google.getLEI=function(a){for(var b=null;a&&(!a.getAttribute||!(b=a.getAttribute(\"leid\")));)a=a.parentNode;return b};google.https=function(){return\"https:\"==window.location.protocol};google.ml=function(){return null};google.time=function(){return(new Date).getTime()};google.log=function(a,b,e,c,g){if(a=google.logUrl(a,b,e,c,g)){b=new Image;var d=google.lc,f=google.li;d[f]=b;b.onerror=b.onload=b.onabort=function(){delete d[f]};google.vel&&google.vel.lu&&google.vel.lu(a);b.src=a;google.li=f+1}};google.logUrl=function(a,b,e,c,g){var d=\"\",f=google.ls||\"\";e||-1!=b.search(\"&ei=\")||(d=\"&ei=\"+google.getEI(c),-1==b.search(\"&lei=\")&&(c=google.getLEI(c))&&(d+=\"&lei=\"+c));c=\"\";!e&&google.cshid&&-1==b.search(\"&cshid=\")&&\"slh\"!=a&&(c=\"&cshid=\"+google.cshid);a=e||\"/\"+(g||\"gen_204\")+\"?atyp=i&ct=\"+a+\"&cad=\"+b+d+f+\"&zx=\"+google.time()+c;/^http:/i.test(a)&&google.https()&&(google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a};}).call(this);(function(){google.y={};google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};}).call(this);google.f={};var a=window.location,b=a.href.indexOf(\"#\");if(0<=b){var c=a.href.substring(b+1);/(^|&)q=/.test(c)&&-1==c.indexOf(\"#\")&&a.replace(\"/search?\"+c.replace(/(^|&)fp=[^&]*/g,\"\")+\"&cad=h\")};</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}\n",
      "</style><style>body,td,a,p,.h{font-family:arial,sans-serif}body{margin:0;overflow-y:scroll}#gog{padding:3px 8px 0}td{line-height:.8em}.gac_m td{line-height:17px}form{margin-bottom:20px}.h{color:#36c}.q{color:#00c}.ts td{padding:0}.ts{border-collapse:collapse}em{font-weight:bold;font-style:normal}.lst{height:25px;width:496px}.gsfi,.lst{font:18px arial,sans-serif}.gsfs{font:17px arial,sans-serif}.ds{display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px}input{font-family:inherit}a.gb1,a.gb2,a.gb3,a.gb4{color:#11c !important}body{background:#fff;color:black}a{color:#11c;text-decoration:none}a:hover,a:active{text-decoration:underline}.fl a{color:#36c}a:visited{color:#551a8b}a.gb1,a.gb4{text-decoration:underline}a.gb3:hover{text-decoration:none}#ghead a.gb2:hover{color:#fff !important}.sblc{padding-top:5px}.sblc a{display:block;margin:2px 0;margin-left:13px;font-size:11px}.lsbb{background:#eee;border:solid 1px;border-color:#ccc #999 #999 #ccc;height:30px}.lsbb{display:block}.ftl,#fll a{display:inline-block;margin:0 12px}.lsb{background:url(/images/nav_logo229.png) 0 -261px repeat-x;border:none;color:#000;cursor:pointer;height:30px;margin:0;outline:0;font:15px arial,sans-serif;vertical-align:top}.lsb:active{background:#ccc}.lst:focus{outline:none}</style><script nonce=\"jBBjMw5yWe8dNPI6XeutIA==\"></script></head><body bgcolor=\"#fff\"><script nonce=\"jBBjMw5yWe8dNPI6XeutIA==\">(function(){var src='/images/nav_logo229.png';var iesg=false;document.body.onload = function(){window.n && window.n();if (document.images){new Image().src=src;}\n",
      "if (!iesg){document.f&&document.f.q.focus();document.gbqf&&document.gbqf.q.focus();}\n",
      "}\n",
      "})();</script><div id=\"mngb\"> <div id=gbar><nobr><b class=gb1>Búsqueda</b> <a class=gb1 href=\"http://www.google.es/imghp?hl=es&tab=wi\">Imágenes</a> <a class=gb1 href=\"http://maps.google.es/maps?hl=es&tab=wl\">Maps</a> <a class=gb1 href=\"https://play.google.com/?hl=es&tab=w8\">Play</a> <a class=gb1 href=\"http://www.youtube.com/?gl=ES&tab=w1\">YouTube</a> <a class=gb1 href=\"http://news.google.es/nwshp?hl=es&tab=wn\">Noticias</a> <a class=gb1 href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a> <a class=gb1 href=\"https://drive.google.com/?tab=wo\">Drive</a> <a class=gb1 style=\"text-decoration:none\" href=\"https://www.google.es/intl/es/about/products?tab=wh\"><u>Más</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a href=\"http://www.google.es/history/optout?hl=es\" class=gb4>Historial web</a> | <a  href=\"/preferences?hl=es\" class=gb4>Configuración</a> | <a target=_top id=gb_70 href=\"https://accounts.google.com/ServiceLogin?hl=es&passive=true&continue=http://www.google.com/\" class=gb4>Iniciar sesión</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div> </div><center><br clear=\"all\" id=\"lgpd\"><div id=\"lga\"><img alt=\"Google\" height=\"92\" src=\"/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\" style=\"padding:28px 0 14px\" width=\"272\" id=\"hplogo\"><br><br></div><form action=\"/search\" name=\"f\"><table cellpadding=\"0\" cellspacing=\"0\"><tr valign=\"top\"><td width=\"25%\">&nbsp;</td><td align=\"center\" nowrap=\"\"><input name=\"ie\" value=\"ISO-8859-1\" type=\"hidden\"><input value=\"es\" name=\"hl\" type=\"hidden\"><input name=\"source\" type=\"hidden\" value=\"hp\"><input name=\"biw\" type=\"hidden\"><input name=\"bih\" type=\"hidden\"><div class=\"ds\" style=\"height:32px;margin:4px 0\"><input style=\"color:#000;margin:0;padding:5px 8px 0 6px;vertical-align:top\" autocomplete=\"off\" class=\"lst\" value=\"\" title=\"Buscar con Google\" maxlength=\"2048\" name=\"q\" size=\"57\"></div><br style=\"line-height:0\"><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" value=\"Buscar con Google\" name=\"btnG\" type=\"submit\"></span></span><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" id=\"tsuid1\" value=\"Voy a tener suerte\" name=\"btnI\" type=\"submit\"><script nonce=\"jBBjMw5yWe8dNPI6XeutIA==\">(function(){var id='tsuid1';document.getElementById(id).onclick = function(){if (this.form.q.value){this.checked = 1;if (this.form.iflsig)this.form.iflsig.disabled = false;}\n",
      "else top.location='/doodles/';};})();</script><input value=\"AAP1E1EAAAAAXa86w3pRgniky5SFEp-hboAoFIyFKXpl\" name=\"iflsig\" type=\"hidden\"></span></span></td><td class=\"fl sblc\" align=\"left\" nowrap=\"\" width=\"25%\"><a href=\"/advanced_search?hl=es&amp;authuser=0\">Búsqueda avanzada</a><a href=\"/language_tools?hl=es&amp;authuser=0\">Herramientas del idioma</a></td></tr></table><input id=\"gbv\" name=\"gbv\" type=\"hidden\" value=\"1\"><script nonce=\"jBBjMw5yWe8dNPI6XeutIA==\">(function(){var a,b=\"1\";if(document&&document.getElementById)if(\"undefined\"!=typeof XMLHttpRequest)b=\"2\";else if(\"undefined\"!=typeof ActiveXObject){var c,d,e=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"];for(c=0;d=e[c++];)try{new ActiveXObject(d),b=\"2\"}catch(h){}}a=b;if(\"2\"==a&&-1==location.search.indexOf(\"&gbv=2\")){var f=google.gbvu,g=document.getElementById(\"gbv\");g&&(g.value=a);f&&window.setTimeout(function(){location.href=f},0)};}).call(this);</script></form><div id=\"gac_scont\"></div><div style=\"font-size:83%;min-height:3.5em\"><br><div id=\"prm\"><style>.szppmdbYutt__middle-slot-promo{font-size:small;margin-bottom:32px}.szppmdbYutt__middle-slot-promo a.ZIeIlb{display:inline-block;text-decoration:none}.szppmdbYutt__middle-slot-promo img{border:none;margin-right:5px;vertical-align:middle}</style><div class=\"szppmdbYutt__middle-slot-promo\" data-ved=\"0ahUKEwjg5Lueo7DlAhUwx4UKHQc8APUQnIcBCAQ\"><span style=\"color:#ff0000\">¡Novedad! </span><a class=\"NKcBbd\" href=\"https://www.google.com/url?q=https://store.google.com/product/google_nest_mini%3Futm_source%3Dhpp%26utm_medium%3Dgoogle_oo%26utm_campaign%3DGS103618%26utm_content%3Dbrand&amp;source=hpp&amp;id=19014416&amp;ct=3&amp;usg=AFQjCNGzDl0p_RpWmdUTmMbG00_Im0sPSg&amp;sa=X&amp;ved=0ahUKEwjg5Lueo7DlAhUwx4UKHQc8APUQ8IcBCAU\" rel=\"nofollow\">Nest Mini ya está disponible en Google Store</a></div></div><div id=\"gws-output-pages-elements-homepage_additional_languages__als\"><style>#gws-output-pages-elements-homepage_additional_languages__als{font-size:small;margin-bottom:24px}#SIvCob{display:inline-block;line-height:28px;}#SIvCob a{padding:0 3px;}.H6sW5{display:inline-block;margin:0 2px;white-space:nowrap}.z4hgWe{display:inline-block;margin:0 2px}</style><div id=\"SIvCob\">Ofrecido por Google en:  <a href=\"http://www.google.com/setprefs?sig=0_OxOnfPksH8Wmhp3akpwPV8hiF68%3D&amp;hl=ca&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjg5Lueo7DlAhUwx4UKHQc8APUQ2ZgBCAc\">català</a>    <a href=\"http://www.google.com/setprefs?sig=0_OxOnfPksH8Wmhp3akpwPV8hiF68%3D&amp;hl=gl&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjg5Lueo7DlAhUwx4UKHQc8APUQ2ZgBCAg\">galego</a>    <a href=\"http://www.google.com/setprefs?sig=0_OxOnfPksH8Wmhp3akpwPV8hiF68%3D&amp;hl=eu&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjg5Lueo7DlAhUwx4UKHQc8APUQ2ZgBCAk\">euskara</a>  </div></div></div><span id=\"footer\"><div style=\"font-size:10pt\"><div style=\"margin:19px auto;text-align:center\" id=\"fll\"><a href=\"/intl/es/ads/\">Programas de publicidad</a><a href=\"http://www.google.es/intl/es/services/\">Soluciones Empresariales</a><a href=\"/intl/es/about.html\">Todo acerca de Google</a><a href=\"http://www.google.com/setprefdomain?prefdom=ES&amp;prev=http://www.google.es/&amp;sig=K_vJlTb5a2ZDLorvITSTwn_Ja5-sE%3D\">Google.es</a></div></div><p style=\"color:#767676;font-size:8pt\">&copy; 2019 - <a href=\"/intl/es/policies/privacy/\">Privacidad</a> - <a href=\"/intl/es/policies/terms/\">Condiciones</a></p></span></center><script nonce=\"jBBjMw5yWe8dNPI6XeutIA==\">(function(){window.google.cdo={height:0,width:0};(function(){var a=window.innerWidth,b=window.innerHeight;if(!a||!b){var c=window.document,d=\"CSS1Compat\"==c.compatMode?c.documentElement:c.body;a=d.clientWidth;b=d.clientHeight}a&&b&&(a!=google.cdo.width||b!=google.cdo.height)&&google.log(\"\",\"\",\"/client_204?&atyp=i&biw=\"+a+\"&bih=\"+b+\"&ei=\"+google.kEI);}).call(this);})();(function(){var u='/xjs/_/js/k\\x3dxjs.hp.en.KD9JaXt6YxI.O/m\\x3dsb_he,d/am\\x3dwAlsBg/d\\x3d1/rs\\x3dACT90oFvmtUXTmOL14_0jkOUZUSwFxNMNw';setTimeout(function(){var a=document.createElement(\"script\");a.src=u;google.timers&&google.timers.load&&google.tick&&google.tick(\"load\",\"xjsls\");document.body.appendChild(a)},0);})();(function(){window.google.xjsu='/xjs/_/js/k\\x3dxjs.hp.en.KD9JaXt6YxI.O/m\\x3dsb_he,d/am\\x3dwAlsBg/d\\x3d1/rs\\x3dACT90oFvmtUXTmOL14_0jkOUZUSwFxNMNw';})();function _DumpException(e){throw e;}\n",
      "function _F_installCss(c){}\n",
      "(function(){google.spjs=false;google.snet=true;google.em=[];google.emw=false;})();(function(){var pmc='{\\x22CaHQXQ\\x22:{},\\x22Qnk92g\\x22:{},\\x22RWGcrA\\x22:{},\\x22U5B21g\\x22:{},\\x22YFCs/g\\x22:{},\\x22ZI/YVQ\\x22:{},\\x22d\\x22:{},\\x22mVopag\\x22:{},\\x22sb_he\\x22:{\\x22agen\\x22:true,\\x22cgen\\x22:true,\\x22client\\x22:\\x22heirloom-hp\\x22,\\x22dh\\x22:true,\\x22dhqt\\x22:true,\\x22ds\\x22:\\x22\\x22,\\x22ffql\\x22:\\x22es\\x22,\\x22fl\\x22:true,\\x22host\\x22:\\x22google.com\\x22,\\x22isbh\\x22:28,\\x22jsonp\\x22:true,\\x22lm\\x22:true,\\x22msgs\\x22:{\\x22cibl\\x22:\\x22Borrar búsqueda\\x22,\\x22dym\\x22:\\x22Quizás quisiste decir:\\x22,\\x22lcky\\x22:\\x22Voy a tener suerte\\x22,\\x22lml\\x22:\\x22Más información\\x22,\\x22oskt\\x22:\\x22Herramientas de introducción de texto\\x22,\\x22psrc\\x22:\\x22Esta búsqueda se ha eliminado de tu \\\\u003Ca href\\x3d\\\\\\x22/history\\\\\\x22\\\\u003Ehistorial web\\\\u003C/a\\\\u003E.\\x22,\\x22psrl\\x22:\\x22Eliminar\\x22,\\x22sbit\\x22:\\x22Buscar por imagen\\x22,\\x22srch\\x22:\\x22Buscar con Google\\x22},\\x22ovr\\x22:{},\\x22pq\\x22:\\x22\\x22,\\x22refpd\\x22:true,\\x22rfs\\x22:[],\\x22sbpl\\x22:24,\\x22sbpr\\x22:24,\\x22scd\\x22:10,\\x22sce\\x22:5,\\x22stok\\x22:\\x228iAQHSa1VBmwHwhni7I5i0Gzyro\\x22,\\x22uhde\\x22:false}}';google.pmc=JSON.parse(pmc);})();</script>        </body></html>\n"
     ]
    }
   ],
   "source": [
    "#Check on something\n",
    "print(something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n"
     ]
    }
   ],
   "source": [
    "#What!!!!\n",
    "#Let us read more\n",
    "print(source.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ooooppss nothing else.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, hands on!!! Some first warm up exercises:\n",
    "\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**WARM UP EXERCISES**\n",
    "<ol>\n",
    "<li>Is there the word python in pyladies.org?</li>\n",
    "<li>Does http://google.com contain an image? (hint: < img > TAG )</li>\n",
    "<li>What are the first ten characters of python.org?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype \n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "from urllib.request import urlopen\n",
    "\n",
    "pylad = urlopen(\"http://www.python.org\").read().decode('latin-1')\n",
    "\n",
    "'python' in pylad\n",
    "\n",
    "print(pylad[0:10])\n",
    "#print (pylad.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are retrieving data from an URL! So we are done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling and Scraping\n",
    "\n",
    "Scraping and **crawling** are two very related techniques. While scraping is used for retrieving data from a web page, crawling is used to retrieve the web pages. Scraping and crawling are found at the core of search engines. Scraping is used to get keywords, analyze, and extract useful information from the web pages so that given a user query it may return related results. On the other hand, crawling allows to retrieve the actual pages and uses scraping to get the links in each web site. This allows to create a graph of the connection among web sites and this information can be used to order the results of a query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we might want not only to get data from a single page but probably retrieve from several related pages. In those cases crawling is the way to go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**WARM-UP PROJECT:** Let us build a very simple spider. The basic functionality of an spider is to crawl and store all the data in web pages. In this simple project we will take care of single site. \n",
    "\n",
    "<ol>\n",
    "<li>A crawler must recognize the links to crawl. Take a minute and think how to retrieve the links of a web site.</li>\n",
    "<li>Let us start the project by creating a Spider class. The constructor will have the following parameters: starting_url, crawl_domain, and max_iter. crawl_domain will be the domain that validates if an absolute link will be considered or not. max_iter is the maximum amount of web items to crawl.</li>\n",
    "<li>The main method can be Spider.run(). Enumerate the big functionalities/building blocks of the crawler.</li>\n",
    "</ol>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import time\n",
    "\n",
    "def getLinks(html, max_links=10):\n",
    "    url = []\n",
    "    cursor = 0\n",
    "    nlinks=0\n",
    "    while (cursor>=0 and nlinks<max_links):\n",
    "        start_link = html.find(\"a href\",cursor)\n",
    "        if start_link==-1:\n",
    "            return url\n",
    "        start_quote = html.find('\"', start_link)\n",
    "        end_quote = html.find('\"', start_quote + 1)\n",
    "        url.append(html[start_quote + 1: end_quote])\n",
    "        cursor = end_quote+1\n",
    "        nlinks = nlinks +1\n",
    "    return url\n",
    "\n",
    "class Spider:\n",
    "    def __init__(self,starting_url,crawl_domain,max_iter):\n",
    "        self.crawl_domain = crawl_domain\n",
    "        self.max_iter = max_iter\n",
    "        self.links_to_crawl=[]\n",
    "        self.links_to_crawl.append(starting_url)\n",
    "        self.links_visited=[]\n",
    "        self.collection=[]\n",
    "        \n",
    "    def retrieveHtml(self):\n",
    "        try:\n",
    "            socket = urlopen(self.url);\n",
    "            self.html = socket.read().decode('latin-1')\n",
    "            return 0\n",
    "        except HTTPError:\n",
    "            # Most probably an url not found 404, possibly due to malformating of the links in retrieveAndValidateLinks\n",
    "            return -1\n",
    "             \n",
    "    def run(self):\n",
    "        while (len(self.links_to_crawl)>0 and len(self.collection)<self.max_iter):\n",
    "            self.url = self.links_to_crawl.pop(0)\n",
    "            print (self.links_to_crawl)\n",
    "            self.links_visited.append(self.url)\n",
    "            if self.retrieveHtml()>=0:\n",
    "                self.storeHtml()\n",
    "                self.retrieveAndValidateLinks()\n",
    "    \n",
    "    def retrieveAndValidateLinks(self):\n",
    "        tmpList=[]\n",
    "        items = getLinks(self.html)\n",
    "        # Check the validity of a link\n",
    "        for item in items:\n",
    "            item = item.strip('\"')\n",
    "            if self.crawl_domain in item:\n",
    "                tmpList.append(item)\n",
    "            if not(\":\") in item: #Take care of http:// https:// and mailto:\n",
    "                tmpList.append(self.crawl_domain+item)\n",
    "        # Check that the link has not been previously retrieved or is currently on the links_to_crawl list\n",
    "        for item in tmpList:\n",
    "            if item not in self.links_visited:\n",
    "                if item not in self.links_to_crawl:\n",
    "                    self.links_to_crawl.append(item)\n",
    "                    print ('Adding: '+item)\n",
    "                \n",
    "    def storeHtml(self):\n",
    "        doc = {}\n",
    "        doc['url'] = self.url\n",
    "        doc['date'] = time.strftime(\"%d/%m/%Y\")\n",
    "        doc['html'] = self.html\n",
    "        self.collection.append(doc)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us validate the crawler with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/index.html\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/whatisdatascience.html\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/content.html\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/apply.html\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/faq.html\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/about.html\n",
      "['http://www.ub.edu/datascience/postgraduate/whatisdatascience.html', 'http://www.ub.edu/datascience/postgraduate/content.html', 'http://www.ub.edu/datascience/postgraduate/apply.html', 'http://www.ub.edu/datascience/postgraduate/faq.html', 'http://www.ub.edu/datascience/postgraduate/about.html']\n",
      "['http://www.ub.edu/datascience/postgraduate/content.html', 'http://www.ub.edu/datascience/postgraduate/apply.html', 'http://www.ub.edu/datascience/postgraduate/faq.html', 'http://www.ub.edu/datascience/postgraduate/about.html']\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/academics.html\n",
      "Adding: http://www.ub.edu/datascience/postgraduate/blog.html\n",
      "['http://www.ub.edu/datascience/postgraduate/apply.html', 'http://www.ub.edu/datascience/postgraduate/faq.html', 'http://www.ub.edu/datascience/postgraduate/about.html', 'http://www.ub.edu/datascience/postgraduate/academics.html', 'http://www.ub.edu/datascience/postgraduate/blog.html']\n",
      "['http://www.ub.edu/datascience/postgraduate/faq.html', 'http://www.ub.edu/datascience/postgraduate/about.html', 'http://www.ub.edu/datascience/postgraduate/academics.html', 'http://www.ub.edu/datascience/postgraduate/blog.html']\n",
      "['http://www.ub.edu/datascience/postgraduate/about.html', 'http://www.ub.edu/datascience/postgraduate/academics.html', 'http://www.ub.edu/datascience/postgraduate/blog.html']\n",
      "['http://www.ub.edu/datascience/postgraduate/academics.html', 'http://www.ub.edu/datascience/postgraduate/blog.html']\n",
      "['http://www.ub.edu/datascience/postgraduate/blog.html']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "spider = Spider('http://www.ub.edu/datascience/postgraduate/','http://www.ub.edu/datascience/postgraduate/',20)\n",
    "spider.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Howmany elements does our colletion have?\n",
    "len(spider.collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://hunch.net/?p=12224166',\n",
       " 'date': '22/10/2019',\n",
       " 'html': '<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en-US\">\\n\\n<head profile=\"http://gmpg.org/xfn/11\">\\n\\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n\\n\\t<title>ICML has 3(!) Real World Reinforcement Learning Workshops &laquo;  Machine Learning (Theory)</title>\\n\\n\\t<style type=\"text/css\" media=\"screen\">\\n\\t\\t@import url( http://hunch.net/wp-content/themes/classic_modified/style.css );\\n\\t</style>\\n\\n\\t<link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS 2.0\" href=\"http://hunch.net/?feed=rss2\" />\\n\\t<link rel=\"alternate\" type=\"text/xml\" title=\"RSS .92\" href=\"http://hunch.net/?feed=rss\" />\\n\\t<link rel=\"alternate\" type=\"application/atom+xml\" title=\"Atom 1.0\" href=\"http://hunch.net/?feed=atom\" />\\n\\n\\t<link rel=\"pingback\" href=\"http://hunch.net/xmlrpc.php\" />\\n\\t\\t<link rel=\\'archives\\' title=\\'June 2019\\' href=\\'http://hunch.net/?m=201906\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2019\\' href=\\'http://hunch.net/?m=201902\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2018\\' href=\\'http://hunch.net/?m=201812\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2018\\' href=\\'http://hunch.net/?m=201811\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2018\\' href=\\'http://hunch.net/?m=201810\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2018\\' href=\\'http://hunch.net/?m=201807\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2018\\' href=\\'http://hunch.net/?m=201806\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2018\\' href=\\'http://hunch.net/?m=201804\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2018\\' href=\\'http://hunch.net/?m=201803\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2018\\' href=\\'http://hunch.net/?m=201802\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2017\\' href=\\'http://hunch.net/?m=201712\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2017\\' href=\\'http://hunch.net/?m=201708\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2017\\' href=\\'http://hunch.net/?m=201707\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2017\\' href=\\'http://hunch.net/?m=201706\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2017\\' href=\\'http://hunch.net/?m=201704\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2017\\' href=\\'http://hunch.net/?m=201701\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2016\\' href=\\'http://hunch.net/?m=201612\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2016\\' href=\\'http://hunch.net/?m=201608\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2016\\' href=\\'http://hunch.net/?m=201607\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2016\\' href=\\'http://hunch.net/?m=201606\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2016\\' href=\\'http://hunch.net/?m=201605\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2016\\' href=\\'http://hunch.net/?m=201604\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2016\\' href=\\'http://hunch.net/?m=201603\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2016\\' href=\\'http://hunch.net/?m=201602\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2016\\' href=\\'http://hunch.net/?m=201601\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2015\\' href=\\'http://hunch.net/?m=201512\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2015\\' href=\\'http://hunch.net/?m=201511\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2015\\' href=\\'http://hunch.net/?m=201510\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2015\\' href=\\'http://hunch.net/?m=201504\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2015\\' href=\\'http://hunch.net/?m=201501\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2014\\' href=\\'http://hunch.net/?m=201412\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2014\\' href=\\'http://hunch.net/?m=201411\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2014\\' href=\\'http://hunch.net/?m=201410\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2014\\' href=\\'http://hunch.net/?m=201409\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2014\\' href=\\'http://hunch.net/?m=201407\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2014\\' href=\\'http://hunch.net/?m=201406\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2014\\' href=\\'http://hunch.net/?m=201403\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2014\\' href=\\'http://hunch.net/?m=201402\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2013\\' href=\\'http://hunch.net/?m=201312\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2013\\' href=\\'http://hunch.net/?m=201311\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2013\\' href=\\'http://hunch.net/?m=201309\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2013\\' href=\\'http://hunch.net/?m=201308\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2013\\' href=\\'http://hunch.net/?m=201307\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2013\\' href=\\'http://hunch.net/?m=201306\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2013\\' href=\\'http://hunch.net/?m=201305\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2013\\' href=\\'http://hunch.net/?m=201304\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2013\\' href=\\'http://hunch.net/?m=201303\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2013\\' href=\\'http://hunch.net/?m=201301\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2012\\' href=\\'http://hunch.net/?m=201212\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2012\\' href=\\'http://hunch.net/?m=201210\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2012\\' href=\\'http://hunch.net/?m=201209\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2012\\' href=\\'http://hunch.net/?m=201208\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2012\\' href=\\'http://hunch.net/?m=201207\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2012\\' href=\\'http://hunch.net/?m=201206\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2012\\' href=\\'http://hunch.net/?m=201205\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2012\\' href=\\'http://hunch.net/?m=201204\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2012\\' href=\\'http://hunch.net/?m=201203\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2012\\' href=\\'http://hunch.net/?m=201202\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2012\\' href=\\'http://hunch.net/?m=201201\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2011\\' href=\\'http://hunch.net/?m=201112\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2011\\' href=\\'http://hunch.net/?m=201111\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2011\\' href=\\'http://hunch.net/?m=201110\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2011\\' href=\\'http://hunch.net/?m=201109\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2011\\' href=\\'http://hunch.net/?m=201108\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2011\\' href=\\'http://hunch.net/?m=201107\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2011\\' href=\\'http://hunch.net/?m=201106\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2011\\' href=\\'http://hunch.net/?m=201105\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2011\\' href=\\'http://hunch.net/?m=201104\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2011\\' href=\\'http://hunch.net/?m=201103\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2011\\' href=\\'http://hunch.net/?m=201102\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2011\\' href=\\'http://hunch.net/?m=201101\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2010\\' href=\\'http://hunch.net/?m=201012\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2010\\' href=\\'http://hunch.net/?m=201011\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2010\\' href=\\'http://hunch.net/?m=201010\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2010\\' href=\\'http://hunch.net/?m=201009\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2010\\' href=\\'http://hunch.net/?m=201008\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2010\\' href=\\'http://hunch.net/?m=201007\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2010\\' href=\\'http://hunch.net/?m=201006\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2010\\' href=\\'http://hunch.net/?m=201005\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2010\\' href=\\'http://hunch.net/?m=201004\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2010\\' href=\\'http://hunch.net/?m=201003\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2010\\' href=\\'http://hunch.net/?m=201002\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2010\\' href=\\'http://hunch.net/?m=201001\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2009\\' href=\\'http://hunch.net/?m=200912\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2009\\' href=\\'http://hunch.net/?m=200911\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2009\\' href=\\'http://hunch.net/?m=200910\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2009\\' href=\\'http://hunch.net/?m=200909\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2009\\' href=\\'http://hunch.net/?m=200908\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2009\\' href=\\'http://hunch.net/?m=200907\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2009\\' href=\\'http://hunch.net/?m=200906\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2009\\' href=\\'http://hunch.net/?m=200905\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2009\\' href=\\'http://hunch.net/?m=200904\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2009\\' href=\\'http://hunch.net/?m=200903\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2009\\' href=\\'http://hunch.net/?m=200902\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2009\\' href=\\'http://hunch.net/?m=200901\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2008\\' href=\\'http://hunch.net/?m=200812\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2008\\' href=\\'http://hunch.net/?m=200811\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2008\\' href=\\'http://hunch.net/?m=200810\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2008\\' href=\\'http://hunch.net/?m=200809\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2008\\' href=\\'http://hunch.net/?m=200808\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2008\\' href=\\'http://hunch.net/?m=200807\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2008\\' href=\\'http://hunch.net/?m=200806\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2008\\' href=\\'http://hunch.net/?m=200805\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2008\\' href=\\'http://hunch.net/?m=200804\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2008\\' href=\\'http://hunch.net/?m=200803\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2008\\' href=\\'http://hunch.net/?m=200802\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2008\\' href=\\'http://hunch.net/?m=200801\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2007\\' href=\\'http://hunch.net/?m=200712\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2007\\' href=\\'http://hunch.net/?m=200711\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2007\\' href=\\'http://hunch.net/?m=200710\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2007\\' href=\\'http://hunch.net/?m=200709\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2007\\' href=\\'http://hunch.net/?m=200708\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2007\\' href=\\'http://hunch.net/?m=200707\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2007\\' href=\\'http://hunch.net/?m=200706\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2007\\' href=\\'http://hunch.net/?m=200705\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2007\\' href=\\'http://hunch.net/?m=200704\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2007\\' href=\\'http://hunch.net/?m=200703\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2007\\' href=\\'http://hunch.net/?m=200702\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2007\\' href=\\'http://hunch.net/?m=200701\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2006\\' href=\\'http://hunch.net/?m=200612\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2006\\' href=\\'http://hunch.net/?m=200611\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2006\\' href=\\'http://hunch.net/?m=200610\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2006\\' href=\\'http://hunch.net/?m=200609\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2006\\' href=\\'http://hunch.net/?m=200608\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2006\\' href=\\'http://hunch.net/?m=200607\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2006\\' href=\\'http://hunch.net/?m=200606\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2006\\' href=\\'http://hunch.net/?m=200605\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2006\\' href=\\'http://hunch.net/?m=200604\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2006\\' href=\\'http://hunch.net/?m=200603\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2006\\' href=\\'http://hunch.net/?m=200602\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2006\\' href=\\'http://hunch.net/?m=200601\\' />\\n\\t<link rel=\\'archives\\' title=\\'December 2005\\' href=\\'http://hunch.net/?m=200512\\' />\\n\\t<link rel=\\'archives\\' title=\\'November 2005\\' href=\\'http://hunch.net/?m=200511\\' />\\n\\t<link rel=\\'archives\\' title=\\'October 2005\\' href=\\'http://hunch.net/?m=200510\\' />\\n\\t<link rel=\\'archives\\' title=\\'September 2005\\' href=\\'http://hunch.net/?m=200509\\' />\\n\\t<link rel=\\'archives\\' title=\\'August 2005\\' href=\\'http://hunch.net/?m=200508\\' />\\n\\t<link rel=\\'archives\\' title=\\'July 2005\\' href=\\'http://hunch.net/?m=200507\\' />\\n\\t<link rel=\\'archives\\' title=\\'June 2005\\' href=\\'http://hunch.net/?m=200506\\' />\\n\\t<link rel=\\'archives\\' title=\\'May 2005\\' href=\\'http://hunch.net/?m=200505\\' />\\n\\t<link rel=\\'archives\\' title=\\'April 2005\\' href=\\'http://hunch.net/?m=200504\\' />\\n\\t<link rel=\\'archives\\' title=\\'March 2005\\' href=\\'http://hunch.net/?m=200503\\' />\\n\\t<link rel=\\'archives\\' title=\\'February 2005\\' href=\\'http://hunch.net/?m=200502\\' />\\n\\t<link rel=\\'archives\\' title=\\'January 2005\\' href=\\'http://hunch.net/?m=200501\\' />\\n\\t\\t\\t\\t<script type=\"text/javascript\">\\n\\t\\t\\twindow._wpemojiSettings = {\"baseUrl\":\"http:\\\\/\\\\/s.w.org\\\\/images\\\\/core\\\\/emoji\\\\/72x72\\\\/\",\"ext\":\".png\",\"source\":{\"concatemoji\":\"http:\\\\/\\\\/hunch.net\\\\/wp-includes\\\\/js\\\\/wp-emoji-release.min.js?ver=4.3\"}};\\n\\t\\t\\t!function(a,b,c){function d(a){var c=b.createElement(\"canvas\"),d=c.getContext&&c.getContext(\"2d\");return d&&d.fillText?(d.textBaseline=\"top\",d.font=\"600 32px Arial\",\"flag\"===a?(d.fillText(String.fromCharCode(55356,56812,55356,56807),0,0),c.toDataURL().length>3e3):(d.fillText(String.fromCharCode(55357,56835),0,0),0!==d.getImageData(16,16,1,1).data[0])):!1}function e(a){var c=b.createElement(\"script\");c.src=a,c.type=\"text/javascript\",b.getElementsByTagName(\"head\")[0].appendChild(c)}var f,g;c.supports={simple:d(\"simple\"),flag:d(\"flag\")},c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.simple&&c.supports.flag||(g=function(){c.readyCallback()},b.addEventListener?(b.addEventListener(\"DOMContentLoaded\",g,!1),a.addEventListener(\"load\",g,!1)):(a.attachEvent(\"onload\",g),b.attachEvent(\"onreadystatechange\",function(){\"complete\"===b.readyState&&c.readyCallback()})),f=c.source||{},f.concatemoji?e(f.concatemoji):f.wpemoji&&f.twemoji&&(e(f.twemoji),e(f.wpemoji)))}(window,document,window._wpemojiSettings);\\n\\t\\t</script>\\n\\t\\t<style type=\"text/css\">\\nimg.wp-smiley,\\nimg.emoji {\\n\\tdisplay: inline !important;\\n\\tborder: none !important;\\n\\tbox-shadow: none !important;\\n\\theight: 1em !important;\\n\\twidth: 1em !important;\\n\\tmargin: 0 .07em !important;\\n\\tvertical-align: -0.1em !important;\\n\\tbackground: none !important;\\n\\tpadding: 0 !important;\\n}\\n</style>\\n<link rel=\\'stylesheet\\' id=\\'wprssmi_template_styles-css\\'  href=\\'http://hunch.net/wp-content/plugins/wp-rss-multi-importer/templates/templates.css?ver=4.3\\' type=\\'text/css\\' media=\\'all\\' />\\n<script type=\\'text/javascript\\' src=\\'http://hunch.net/wp-includes/js/jquery/jquery.js?ver=1.11.3\\'></script>\\n<script type=\\'text/javascript\\' src=\\'http://hunch.net/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1\\'></script>\\n<link rel=\"EditURI\" type=\"application/rsd+xml\" title=\"RSD\" href=\"http://hunch.net/xmlrpc.php?rsd\" />\\n<link rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\" href=\"http://hunch.net/wp-includes/wlwmanifest.xml\" /> \\n<link rel=\\'prev\\' title=\\'Code submission should be encouraged but not compulsory\\' href=\\'http://hunch.net/?p=11377237\\' />\\n<meta name=\"generator\" content=\"WordPress 4.3\" />\\n<link rel=\\'canonical\\' href=\\'http://hunch.net/?p=12224166\\' />\\n<link rel=\\'shortlink\\' href=\\'http://hunch.net/?p=12224166\\' />\\n\\t<style type=\"text/css\">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>\\n<style type=\"text/css\">\\n/* <![CDATA[ */\\nimg.latex { vertical-align: middle; border: none; }\\n/* ]]> */\\n</style>\\n</head>\\n\\n<body>\\n<div id=\"rap\">\\n<h1 id=\"header\"><a href=\"http://hunch.net/\">Machine Learning (Theory)</a></h1>\\n\\n<div id=\"content\">\\n<!-- end header -->\\n\\n\\n<h2>6/7/2019</h2>\\n<div class=\"post-12224166 post type-post status-publish format-standard hentry category-reinforcement category-workshop\" id=\"post-12224166\">\\n\\t <h3 class=\"storytitle\"><a href=\"http://hunch.net/?p=12224166\" rel=\"bookmark\">ICML has 3(!) Real World Reinforcement Learning Workshops</a></h3>\\n\\t<div class=\"meta\">Tags: <a href=\"http://hunch.net/?cat=11\" rel=\"category\">Reinforcement</a>,<a href=\"http://hunch.net/?cat=41\" rel=\"category\">Workshop</a> &#8212;  <a href=\"http://hunch.net/~jl\"> jl</a>@ 9:28 am </div>\\n\\n\\t<div class=\"storycontent\">\\n\\t\\t<p>The first is <a href=\"https://vowpalwabbit.github.io/icml2019/\">Sunday afternon</a> during the <a href=\"https://icml.cc/Expo/Conferences/2019/Schedule_overview?presentation_type=All\">Industry Expo day</a>.  This one is meant to be quite practical, starting with an overview of Contextual Bandits and leading into how to apply the new <a href=\"https://azure.microsoft.com/en-us/services/cognitive-services/personalizer/\">Personalizer</a> service, the first service in the world functionally supporting  general contextual bandit learning.  </p>\\n<p>The second is <a href=\"https://sites.google.com/view/RL4RealLife\">Friday morning</a>.  This one is more academic with many topics.  I&#8217;ll personally be discussing research questions for real world RL.  </p>\\n<p>The third one is <a href=\"https://realworld-sdm.github.io/\">Friday afternoon</a> with more emphasis on sequences of decisions.  I expect to here &#8220;imitation learning&#8221; multiple times <img src=\"http://hunch.net/wp-includes/images/smilies/simple-smile.png\" alt=\":-)\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /></p>\\n<p>I&#8217;m planning to attend all 3.  It&#8217;s great to see interest building in this direction, because Real World RL seems like the most promising direction for fruitfully expanding the scope of solvable machine learning problems.</p>\\n\\t</div>\\n\\n\\t<div class=\"feedback\">\\n\\t\\t\\t\\t<span>Comments Off<span class=\"screen-reader-text\"> on ICML has 3(!) Real World Reinforcement Learning Workshops</span></span>\\t</div>\\n\\n</div>\\n\\n<div id=\"comments-wrap\">\\n\\n<!-- You can start editing here. -->\\n\\n\\t\\t\\t<!-- If comments are closed. -->\\n\\t\\t<p>Sorry, the comment form is closed at this time.</p>\\n\\n\\t\\n<p>Sorry, the comment form is closed at this time.</p>\\n</div>\\n\\n\\n\\n<!-- begin footer -->\\n</div>\\n\\n\\t<div id=\"menu\">\\n\\t\\t<ul>\\n\\t\\t\\t<li id=\"pages-2\" class=\"widget widget_pages\"><h2 class=\"widgettitle\">Details</h2>\\t\\t<ul>\\n\\t\\t\\t<li class=\"page_item page-item-1115\"><a href=\"http://hunch.net/?page_id=1115\">A modest proposal</a></li>\\n<li class=\"page_item page-item-270\"><a href=\"http://hunch.net/?page_id=270\">How to Contribute a Post</a></li>\\n<li class=\"page_item page-item-122\"><a href=\"http://hunch.net/?page_id=122\">Who? What? Why?</a></li>\\n<li class=\"page_item page-item-284\"><a href=\"http://hunch.net/?page_id=284\">Why did my comment not appear?</a></li>\\n\\t\\t</ul>\\n\\t\\t</li><li id=\"search-2\" class=\"widget widget_search\"><form role=\"search\" method=\"get\" id=\"searchform\" class=\"searchform\" action=\"http://hunch.net/\">\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t<label class=\"screen-reader-text\" for=\"s\">Search for:</label>\\n\\t\\t\\t\\t\\t<input type=\"text\" value=\"\" name=\"s\" id=\"s\" />\\n\\t\\t\\t\\t\\t<input type=\"submit\" id=\"searchsubmit\" value=\"Search\" />\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</form></li><li id=\"text-434477671\" class=\"widget widget_text\">\\t\\t\\t<div class=\"textwidget\"><p><a href=\"http://feeds2.feedburner.com/MachineLearningtheory\" rel=\"alternate\" type=\"application/rss+xml\"><img src=\"http://www.feedburner.com/fb/images/pub/feed-icon16x16.png\" alt=\"\" style=\"vertical-align:middle;border:0\"/></a>&nbsp;<a href=\"http://feeds2.feedburner.com/MachineLearningtheory\" rel=\"alternate\" type=\"application/rss+xml\">Subscribe </a></p></div>\\n\\t\\t</li><li id=\"recent-comments-2\" class=\"widget widget_recent_comments\"><h2 class=\"widgettitle\">Recent Comments</h2><ul id=\"recentcomments\"><li class=\"recentcomments\"><span class=\"comment-author-link\"><a href=\\'https://dipendramisra.wordpress.com/2019/08/08/growing-bifurcation-of-ai-scholarship/\\' rel=\\'external nofollow\\' class=\\'url\\'>Growing Bifurcation of AI Scholarship &#8211; Dipendra Misra</a></span> on <a href=\"http://hunch.net/?page_id=1115&#038;cpage=1#comment-3092799\">A modest proposal</a></li><li class=\"recentcomments\"><span class=\"comment-author-link\"><a href=\\'http://hunch.net/~jl\\' rel=\\'external nofollow\\' class=\\'url\\'>jl</a></span> on <a href=\"http://hunch.net/?p=11377237&#038;cpage=1#comment-3091733\">Code submission should be encouraged but not compulsory</a></li><li class=\"recentcomments\"><span class=\"comment-author-link\">Robert Rand</span> on <a href=\"http://hunch.net/?p=11377237&#038;cpage=1#comment-3091709\">Code submission should be encouraged but not compulsory</a></li><li class=\"recentcomments\"><span class=\"comment-author-link\"><a href=\\'http://hunch.net/?p=11377237\\' rel=\\'external nofollow\\' class=\\'url\\'>Code submission should be encouraged but not compulsory &laquo; Machine Learning (Theory)</a></span> on <a href=\"http://hunch.net/?p=11007870&#038;cpage=1#comment-3091669\">FAQ on ICML 2019 Code Submission Policy</a></li><li class=\"recentcomments\"><span class=\"comment-author-link\"><a href=\\'https://aikindaguy.com/daily-artificial-intelligence-news-roundup-129/\\' rel=\\'external nofollow\\' class=\\'url\\'>Daily Artificial Intelligence News Roundup #129 | Daily Artificial Intelligence &amp; Machine Learning Curated News</a></span> on <a href=\"http://hunch.net/?p=10858918&#038;cpage=1#comment-3091381\">ICML 2019: Some Changes and Call for Papers</a></li></ul></li><li id=\"rss_multi_importer_widget-2\" class=\"widget widget_rss_multi_importer_widget\"><h2 class=\"widgettitle\">RSS Feeds</h2> <div class=\"news-wrapper\" id=\"newsticker\" style=\"10px;background-color:#ffffff;\">\\t<div class=\"news-contents\"><div style=\"top: 101px;margin-left:5px;\" class=\"news\"><div class=\"rssmi_title_class\"><a class=\"colorbox\" href=\"https://blog.computationalcomplexity.org/2019/10/differentiation-and-integration.html\" class=\"news_title\">Differentiation and Integration</a></div>Mon, Oct 21, 2019<br /><span class=\"rssmi_group_style\" style=\"font-style:italic;\">Computational Complexity</span></div><div style=\"top: 101px;margin-left:5px;\" class=\"news\"><div class=\"rssmi_title_class\"><a class=\"colorbox\" href=\"https://www.trifacta.com/blog/snowflake-data-warehouse-best-practices/\" class=\"news_title\">Data Preparation Best Practices for Snowflake&rsquo;s Cloud Data Warehouse</a></div>Tue, Oct 01, 2019<br /><span class=\"rssmi_group_style\" style=\"font-style:italic;\">Data Wrangling</span></div><div style=\"top: 101px;margin-left:5px;\" class=\"news\"><div class=\"rssmi_title_class\"><a class=\"colorbox\" href=\"http://math.andrej.com/2019/09/09/on-complete-ordered-fields/\" class=\"news_title\">On complete ordered fields</a></div>Sun, Sep 08, 2019<br /><span class=\"rssmi_group_style\" style=\"font-style:italic;\">Mathematics and Computation</span></div><div style=\"top: 101px;margin-left:5px;\" class=\"news\"><div class=\"rssmi_title_class\"><a class=\"colorbox\" href=\"https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/\" class=\"news_title\">Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part II</a></div>Wed, Jul 17, 2019<br /><span class=\"rssmi_group_style\" style=\"font-style:italic;\">Im a bandit</span></div><div style=\"top: 101px;margin-left:5px;\" class=\"news\"><div class=\"rssmi_title_class\"><a class=\"colorbox\" href=\"https://dabacon.org/pontiff/2019/07/11/the-open-access-wars/\" class=\"news_title\">The open access wars</a></div>Thu, Jul 11, 2019<br /><span class=\"rssmi_group_style\" style=\"font-style:italic;\">Quantum Pontiff</span></div></div></div></li><li id=\"categories-434403741\" class=\"widget widget_categories\"><h2 class=\"widgettitle\">Categories</h2>\\t\\t<ul>\\n\\t<li class=\"cat-item cat-item-22\"><a href=\"http://hunch.net/?cat=22\" >Active</a> (12)\\n</li>\\n\\t<li class=\"cat-item cat-item-30\"><a href=\"http://hunch.net/?cat=30\" >AI</a> (17)\\n</li>\\n\\t<li class=\"cat-item cat-item-4\"><a href=\"http://hunch.net/?cat=4\" >Announcements</a> (114)\\n</li>\\n\\t<li class=\"cat-item cat-item-35\"><a href=\"http://hunch.net/?cat=35\" >applications</a> (4)\\n</li>\\n\\t<li class=\"cat-item cat-item-6\"><a href=\"http://hunch.net/?cat=6\" >Bayesian</a> (18)\\n</li>\\n\\t<li class=\"cat-item cat-item-53\"><a href=\"http://hunch.net/?cat=53\" >Boosting</a> (1)\\n</li>\\n\\t<li class=\"cat-item cat-item-42\"><a href=\"http://hunch.net/?cat=42\" >Code</a> (17)\\n</li>\\n\\t<li class=\"cat-item cat-item-31\"><a href=\"http://hunch.net/?cat=31\" >Competitions</a> (24)\\n</li>\\n\\t<li class=\"cat-item cat-item-37\"><a href=\"http://hunch.net/?cat=37\" >Computation</a> (6)\\n</li>\\n\\t<li class=\"cat-item cat-item-33\"><a href=\"http://hunch.net/?cat=33\" >Conferences</a> (91)\\n</li>\\n\\t<li class=\"cat-item cat-item-55\"><a href=\"http://hunch.net/?cat=55\" >CS</a> (4)\\n</li>\\n\\t<li class=\"cat-item cat-item-66\"><a href=\"http://hunch.net/?cat=66\" >Deep</a> (4)\\n</li>\\n\\t<li class=\"cat-item cat-item-15\"><a href=\"http://hunch.net/?cat=15\" >Definitions</a> (11)\\n</li>\\n\\t<li class=\"cat-item cat-item-62\"><a href=\"http://hunch.net/?cat=62\" >Economics</a> (3)\\n</li>\\n\\t<li class=\"cat-item cat-item-27\"><a href=\"http://hunch.net/?cat=27\" >Empirical</a> (5)\\n</li>\\n\\t<li class=\"cat-item cat-item-73\"><a href=\"http://hunch.net/?cat=73\" >Exploration</a> (6)\\n</li>\\n\\t<li class=\"cat-item cat-item-23\"><a href=\"http://hunch.net/?cat=23\" >Funding</a> (23)\\n</li>\\n\\t<li class=\"cat-item cat-item-1\"><a href=\"http://hunch.net/?cat=1\" >General</a> (72)\\n</li>\\n\\t<li class=\"cat-item cat-item-63\"><a href=\"http://hunch.net/?cat=63\" >Graduates</a> (2)\\n</li>\\n\\t<li class=\"cat-item cat-item-13\"><a href=\"http://hunch.net/?cat=13\" >Information Theory</a> (4)\\n</li>\\n\\t<li class=\"cat-item cat-item-74\"><a href=\"http://hunch.net/?cat=74\" >Interactive</a> (5)\\n</li>\\n\\t<li class=\"cat-item cat-item-20\"><a href=\"http://hunch.net/?cat=20\" >Language</a> (11)\\n</li>\\n\\t<li class=\"cat-item cat-item-29\"><a href=\"http://hunch.net/?cat=29\" >Machine Learning</a> (322)\\n</li>\\n\\t<li class=\"cat-item cat-item-57\"><a href=\"http://hunch.net/?cat=57\" >Mathematics</a> (2)\\n</li>\\n\\t<li class=\"cat-item cat-item-40\"><a href=\"http://hunch.net/?cat=40\" >MDL</a> (1)\\n</li>\\n\\t<li class=\"cat-item cat-item-68\"><a href=\"http://hunch.net/?cat=68\" >medical</a> (1)\\n</li>\\n\\t<li class=\"cat-item cat-item-36\"><a href=\"http://hunch.net/?cat=36\" >Meta</a> (4)\\n</li>\\n\\t<li class=\"cat-item cat-item-32\"><a href=\"http://hunch.net/?cat=32\" >Neuroscience</a> (2)\\n</li>\\n\\t<li class=\"cat-item cat-item-7\"><a href=\"http://hunch.net/?cat=7\" >Online</a> (38)\\n</li>\\n\\t<li class=\"cat-item cat-item-3\"><a href=\"http://hunch.net/?cat=3\" title=\"Topics on the organization of learning.\">Organization</a> (14)\\n</li>\\n\\t<li class=\"cat-item cat-item-18\"><a href=\"http://hunch.net/?cat=18\" title=\"Discussion of papers\">Papers</a> (45)\\n</li>\\n\\t<li class=\"cat-item cat-item-71\"><a href=\"http://hunch.net/?cat=71\" >parallel</a> (1)\\n</li>\\n\\t<li class=\"cat-item cat-item-79\"><a href=\"http://hunch.net/?cat=79\" >politics</a> (1)\\n</li>\\n\\t<li class=\"cat-item cat-item-8\"><a href=\"http://hunch.net/?cat=8\" >Prediction Theory</a> (20)\\n</li>\\n\\t<li class=\"cat-item cat-item-39\"><a href=\"http://hunch.net/?cat=39\" >Privacy</a> (1)\\n</li>\\n\\t<li class=\"cat-item cat-item-38\"><a href=\"http://hunch.net/?cat=38\" >Problem Design</a> (2)\\n</li>\\n\\t<li class=\"cat-item cat-item-16\"><a href=\"http://hunch.net/?cat=16\" title=\"Learning related problems that may be worth tackling.\">Problems</a> (31)\\n</li>\\n\\t<li class=\"cat-item cat-item-2\"><a href=\"http://hunch.net/?cat=2\" title=\"Open Problems &amp; General questions.\">Questions</a> (3)\\n</li>\\n\\t<li class=\"cat-item cat-item-12\"><a href=\"http://hunch.net/?cat=12\" >Reductions</a> (32)\\n</li>\\n\\t<li class=\"cat-item cat-item-11\"><a href=\"http://hunch.net/?cat=11\" >Reinforcement</a> (29)\\n</li>\\n\\t<li class=\"cat-item cat-item-28\"><a href=\"http://hunch.net/?cat=28\" >Research</a> (52)\\n</li>\\n\\t<li class=\"cat-item cat-item-21\"><a href=\"http://hunch.net/?cat=21\" >Reviewing\\r\\n</a> (23)\\n</li>\\n\\t<li class=\"cat-item cat-item-24\"><a href=\"http://hunch.net/?cat=24\" >Robots</a> (2)\\n</li>\\n\\t<li class=\"cat-item cat-item-9\"><a href=\"http://hunch.net/?cat=9\" >Semisupervised</a> (4)\\n</li>\\n\\t<li class=\"cat-item cat-item-19\"><a href=\"http://hunch.net/?cat=19\" >Solutions</a> (5)\\n</li>\\n\\t<li class=\"cat-item cat-item-34\"><a href=\"http://hunch.net/?cat=34\" >Statistics</a> (6)\\n</li>\\n\\t<li class=\"cat-item cat-item-26\"><a href=\"http://hunch.net/?cat=26\" >structured</a> (7)\\n</li>\\n\\t<li class=\"cat-item cat-item-25\"><a href=\"http://hunch.net/?cat=25\" >Supervised</a> (15)\\n</li>\\n\\t<li class=\"cat-item cat-item-5\"><a href=\"http://hunch.net/?cat=5\" >Teaching</a> (18)\\n</li>\\n\\t<li class=\"cat-item cat-item-48\"><a href=\"http://hunch.net/?cat=48\" >Theory</a> (8)\\n</li>\\n\\t<li class=\"cat-item cat-item-54\"><a href=\"http://hunch.net/?cat=54\" >Trees</a> (2)\\n</li>\\n\\t<li class=\"cat-item cat-item-14\"><a href=\"http://hunch.net/?cat=14\" >Universal Learning</a> (5)\\n</li>\\n\\t<li class=\"cat-item cat-item-10\"><a href=\"http://hunch.net/?cat=10\" >Unsupervised</a> (7)\\n</li>\\n\\t<li class=\"cat-item cat-item-17\"><a href=\"http://hunch.net/?cat=17\" >Vision</a> (6)\\n</li>\\n\\t<li class=\"cat-item cat-item-41\"><a href=\"http://hunch.net/?cat=41\" >Workshop</a> (36)\\n</li>\\n\\t\\t</ul>\\n</li><li id=\"linkcat-44\" class=\"widget widget_links\"><h2 class=\"widgettitle\">ML Related</h2>\\n\\t<ul class=\\'xoxo blogroll\\'>\\n<li><a href=\"http://www.stat.columbia.edu/~gelman/blog/\">Gelman&#8212;SMCISS</a></li>\\n<li><a href=\"http://www.conflate.net/icml/\">ICML Paper Discussion</a></li>\\n<li><a href=\"http://conflate.net/inductio/\">Inductio Ex Machina</a></li>\\n<li><a href=\"http://www.kdnuggets.com/\">KD Nuggets</a></li>\\n<li><a href=\"http://www.kernel-machines.org/phpbb/\">Kernel Machines</a></li>\\n<li><a href=\"http://ml.typepad.com/\">Machine Learning Thoughts</a></li>\\n<li><a href=\"http://mloss.org/community\">MLOSS</a></li>\\n<li><a href=\"http://www.eecs.umich.edu/~baveja/RLmainpage.html\">Reinforcement Learning</a></li>\\n<li><a href=\"http://machine-learning.blogspot.com/\">SM, DM, &amp; ML</a></li>\\n<li><a href=\"http://en.wikipedia.org/wiki/Machine_learning\">Wikipedia: Machine Learning</a></li>\\n\\n\\t</ul>\\n</li>\\n<li id=\"linkcat-72\" class=\"widget widget_links\"><h2 class=\"widgettitle\">Research</h2>\\n\\t<ul class=\\'xoxo blogroll\\'>\\n<li><a href=\"http://weblog.fortnow.com/\">Computational Complexity</a></li>\\n<li><a href=\"http://www.cra.org/govaffairs/blog/\">Computer Research Policy</a></li>\\n<li><a href=\"http://geomblog.blogspot.com/\">Geomblog</a></li>\\n<li><a href=\"http://www.sixthform.info/maths/index.php\">Mathematics</a></li>\\n<li><a href=\"http://math.andrej.com/\">Mathematics and Computation</a></li>\\n<li><a href=\"http://www.michaelnielsen.org/blog/\">Michael Nielsen</a></li>\\n<li><a href=\"http://blog.oddhead.com/\">Oddhead</a></li>\\n<li><a href=\"http://qualgorithms.blogspot.com/\">Quantum Algorithms</a></li>\\n<li><a href=\"http://dabacon.org/pontiff/\">Quantum Pontiff</a></li>\\n\\n\\t</ul>\\n</li>\\n<li id=\"meta-2\" class=\"widget widget_meta\"><h2 class=\"widgettitle\">Meta</h2>\\t\\t\\t<ul>\\n\\t\\t\\t<li><a href=\"http://hunch.net/wp-login.php?action=register\">Register</a></li>\\t\\t\\t<li><a href=\"http://hunch.net/wp-login.php\">Log in</a></li>\\n\\t\\t\\t<li><a href=\"http://hunch.net/?feed=rss2\">Entries <abbr title=\"Really Simple Syndication\">RSS</abbr></a></li>\\n\\t\\t\\t<li><a href=\"http://hunch.net/?feed=comments-rss2\">Comments <abbr title=\"Really Simple Syndication\">RSS</abbr></a></li>\\n<li><a href=\"https://wordpress.org/\" title=\"Powered by WordPress, state-of-the-art semantic personal publishing platform.\">WordPress.org</a></li>\\t\\t\\t</ul>\\n</li>\\t\\t</ul>\\n\\t</div>\\n\\n\\n<p class=\"credit\"><!--131 queries. 0.366 seconds. --> <cite>Powered by <a href=\\'http://wordpress.org/\\' title=\\'Powered by WordPress, state-of-the-art semantic personal publishing platform.\\'><strong>WordPress</strong></a></cite></p>\\n\\n</div>\\n\\n<script type=\\'text/javascript\\'>jQuery(document).ready(function(){ jQuery(\\'a.colorbox\\').colorbox({iframe:true, width:\\'80%\\', height:\\'80%\\'});jQuery(\\'a.rssmi_youtube\\').colorbox({iframe:true, innerWidth:425, innerHeight:344})});</script><link rel=\\'stylesheet\\' id=\\'frontend-css\\'  href=\\'http://hunch.net/wp-content/plugins/wp-rss-multi-importer/css/frontend.css?ver=4.3\\' type=\\'text/css\\' media=\\'all\\' />\\n<link rel=\\'stylesheet\\' id=\\'wprssmi_colorbox-css\\'  href=\\'http://hunch.net/wp-content/plugins/wp-rss-multi-importer/css/colorbox.css?ver=4.3\\' type=\\'text/css\\' media=\\'all\\' />\\n<script type=\\'text/javascript\\' src=\\'http://hunch.net/wp-content/plugins/wp-rss-multi-importer/scripts/show-excerpt.js?ver=4.3\\'></script>\\n<script type=\\'text/javascript\\' src=\\'http://hunch.net/wp-content/plugins/wp-rss-multi-importer/scripts/jquery.colorbox-min.js?ver=4.3\\'></script>\\n<script type=\\'text/javascript\\' src=\\'http://hunch.net/wp-content/plugins/wp-rss-multi-importer/scripts/detect-mobile.js?ver=4.3\\'></script>\\n</body>\\n</html>'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider.collection[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://hunch.net',\n",
       " 'http://hunch.net/',\n",
       " 'http://hunch.net/?p=12224166',\n",
       " 'http://hunch.net/?cat=11',\n",
       " 'http://hunch.net/?cat=41',\n",
       " 'http://hunch.net/~jl',\n",
       " 'http://hunch.net/~mltf',\n",
       " 'http://hunch.net/~rwil',\n",
       " 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf',\n",
       " 'http://hunch.net/~jl/interact.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enumerate the urls retreived\n",
    "[spider.collection[i]['url'] for i in range(len(spider.collection))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go for a more complex web site. Run the code on http://hunch.net (a machine learning blog by John Langford)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Adding: http://hunch.net/\n",
      "Adding: http://hunch.net/?p=12224166\n",
      "Adding: http://hunch.net/?cat=11\n",
      "Adding: http://hunch.net/?cat=41\n",
      "Adding: http://hunch.net/~jl\n",
      "['http://hunch.net/?p=12224166', 'http://hunch.net/?cat=11', 'http://hunch.net/?cat=41', 'http://hunch.net/~jl']\n",
      "['http://hunch.net/?cat=11', 'http://hunch.net/?cat=41', 'http://hunch.net/~jl']\n",
      "['http://hunch.net/?cat=41', 'http://hunch.net/~jl']\n",
      "['http://hunch.net/~jl']\n",
      "[]\n",
      "Adding: http://hunch.net/public_key\n",
      "Adding: http://hunch.net/~mltf\n",
      "Adding: http://hunch.net/~rwil\n",
      "Adding: http://hunch.net/projects/projects.html\n",
      "Adding: http://hunch.net/conferences/conferences.html\n",
      "Adding: http://hunch.net/classes/classes.html\n",
      "Adding: http://hunch.net/resume/resume.html\n",
      "['http://hunch.net/~mltf', 'http://hunch.net/~rwil', 'http://hunch.net/projects/projects.html', 'http://hunch.net/conferences/conferences.html', 'http://hunch.net/classes/classes.html', 'http://hunch.net/resume/resume.html']\n",
      "['http://hunch.net/~rwil', 'http://hunch.net/projects/projects.html', 'http://hunch.net/conferences/conferences.html', 'http://hunch.net/classes/classes.html', 'http://hunch.net/resume/resume.html']\n",
      "Adding: http://hunch.net/MLtF.pptx\n",
      "Adding: http://hunch.net/generalization.pdf\n",
      "Adding: http://hunch.net/generalization.tar.gz\n",
      "Adding: http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf\n",
      "Adding: http://hunch.net/intro_and_samples.mp4\n",
      "['http://hunch.net/projects/projects.html', 'http://hunch.net/conferences/conferences.html', 'http://hunch.net/classes/classes.html', 'http://hunch.net/resume/resume.html', 'http://hunch.net/MLtF.pptx', 'http://hunch.net/generalization.pdf', 'http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4']\n",
      "Adding: http://hunch.net/~jl/interact.pdf\n",
      "Adding: http://hunch.net/Motivation_algs_theory.pptx\n",
      "Adding: http://hunch.net/Stories_systems_issues.pptx\n",
      "Adding: http://hunch.net/Bibliography.pptx\n",
      "['http://hunch.net/conferences/conferences.html', 'http://hunch.net/classes/classes.html', 'http://hunch.net/resume/resume.html', 'http://hunch.net/MLtF.pptx', 'http://hunch.net/generalization.pdf', 'http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/classes/classes.html', 'http://hunch.net/resume/resume.html', 'http://hunch.net/MLtF.pptx', 'http://hunch.net/generalization.pdf', 'http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/resume/resume.html', 'http://hunch.net/MLtF.pptx', 'http://hunch.net/generalization.pdf', 'http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/MLtF.pptx', 'http://hunch.net/generalization.pdf', 'http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/generalization.pdf', 'http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/generalization.tar.gz', 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf', 'http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/intro_and_samples.mp4', 'http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/~jl/interact.pdf', 'http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n",
      "['http://hunch.net/Motivation_algs_theory.pptx', 'http://hunch.net/Stories_systems_issues.pptx', 'http://hunch.net/Bibliography.pptx']\n"
     ]
    }
   ],
   "source": [
    "spider = Spider('http://hunch.net','http://hunch.net/',10)\n",
    "spider.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://hunch.net',\n",
       " 'http://hunch.net/',\n",
       " 'http://hunch.net/?p=12224166',\n",
       " 'http://hunch.net/?cat=11',\n",
       " 'http://hunch.net/?cat=41',\n",
       " 'http://hunch.net/~jl',\n",
       " 'http://hunch.net/~mltf',\n",
       " 'http://hunch.net/~rwil',\n",
       " 'http://hunch.net/~jl/projects/prediction_bounds/tutorial/langford05a.pdf',\n",
       " 'http://hunch.net/~jl/interact.pdf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And check the urls retrieved\n",
    "[spider.collection[i]['url'] for i in range(len(spider.collection))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the simple crawler more or less works as expected. There are still many functionalities to work on , such as valid domains, valid urls, etc. One important issue to consider is **persistence**, or how to store the data retrieved for further analysis. In this basic scraping tutorial we us MongoDB as a Non-SQL database for persistence purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction to MongoDB\n",
    "<small>This introduction is partially inspired on the notes of Alberto Negron's [blog](http://altons.github.io/python/2013/01/21/gentle-introduction-to-mongodb-using-pymongo/)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB is a document-oriented database, part of the NoSQL family of database systems. MongoDB stores structured data as JSON-like structures. From a pythonic point of view it is like storing dictionary data structures. One of its main feature is its schema-less feature, i.e. it supports dynamic schemas. A schema in a relational database informally referst to the structure of the data it stores, i.e. what kind of data, which tables, which relations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us change the Spider class to support MongoDB persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let us configure the MongoDB system.\n",
    "\n",
    "+ Download mongoDB.\n",
    "+ Rename the folder to mongodb.\n",
    "+ Add a directory data and log in your working project directory.\n",
    "+ Check that the server works \n",
    "        mongod --dbpath . --nojournal &\n",
    "+ Check the connection to the server: in another terminal write mongo, check that it does not raise any error and exit the console.\n",
    "+ Close the mongo daemon (mongod). You may have to kill mongod with kill -9 and remove the lock on the daemon, mongod.lock.\n",
    "+ Let us configure a little the data base by configuring the path of the data storage and log files. Create a [mongo.conf](./mongodb/data/mongo.conf) file such as the one provided  and start the server using the following command:\n",
    "\n",
    "        mongod --config=./mongodb/data/mongo.conf --nojournal &\n",
    "+ Bonus: we can check the database status using  http://127.0.0.1:27017/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to a MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connection to Mongo DB\n",
    "try:\n",
    "    conn=pymongo.MongoClient()\n",
    "    print (\"Connected successfully!!!\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e )\n",
    "conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "conn = pymongo.MongoClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **create** a database using attribute access <span style = \"font-family:Courier;\"> db = conn.name_db</span> or dictionary acces <span style = \"font-family:Courier;\"> db = conn[name_db]</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'datascienceUB_Octubre_2016')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: database_names is deprecated. Use list_database_names instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9ab160369c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datascienceUB_Octubre_2016'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#Empty databases do not show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36mdatabase_names\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         warnings.warn(\"database_names is deprecated. Use list_database_names \"\n\u001b[1;32m   1923\u001b[0m                       \"instead.\", DeprecationWarning, stacklevel=2)\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_database_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_database\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36mlist_database_names\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \"\"\"\n\u001b[1;32m   1905\u001b[0m         return [doc[\"name\"]\n\u001b[0;32m-> 1906\u001b[0;31m                 for doc in self.list_databases(session, nameOnly=True)]\n\u001b[0m\u001b[1;32m   1907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdatabase_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36mlist_databases\u001b[0;34m(self, session, **kwargs)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0madmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_database_default_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"admin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retryable_read_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m         \u001b[0;31m# listDatabases doesn't return a cursor (yet). Fake one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         cursor = {\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36m_retryable_read_command\u001b[0;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         return self.__client._retryable_read(\n\u001b[0;32m--> 749\u001b[0;31m             _cmd, read_preference, session)\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     def _list_collections(self, sock_info, slave_okay, session,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_read\u001b[0;34m(self, func, read_pref, session, address, retryable, exhaust)\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m                 server = self._select_server(\n\u001b[0;32m-> 1455\u001b[0;31m                     read_pref, session, address=address)\n\u001b[0m\u001b[1;32m   1456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretryable_reads_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m                     \u001b[0mretryable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_select_server\u001b[0;34m(self, server_selector, session, address)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                                         % address)\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 \u001b[0;31m# Pin this session to the selected server if it's performing a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                 \u001b[0;31m# sharded transaction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    229\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    230\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             server_descriptions = self._select_servers_loop(\n\u001b[0;32m--> 189\u001b[0;31m                 selector, server_timeout, address)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             return [self.get_server_by_address(sd.address)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 205\u001b[0;31m                     self._error_message(selector))\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "#Create a database using db = conn.name_db or dictionary access db = conn['name_db']\n",
    "db = conn['datascienceUB_Octubre_2016']\n",
    "print (db)\n",
    "conn.database_names()\n",
    "#Empty databases do not show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database stores a **collection**. A collection is a group of documents stored in MongoDB, and can be thought of as the equivalent of a table in a relational database. Getting a collection in PyMongo works the same as getting a database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cefdf163142c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hola'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Empty collections do not show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36mcollection_names\u001b[0;34m(self, include_system_collections, session)\u001b[0m\n\u001b[1;32m    879\u001b[0m         return [result[\"name\"]\n\u001b[1;32m    880\u001b[0m                 for result in self.list_collections(session=session,\n\u001b[0;32m--> 881\u001b[0;31m                                                     nameOnly=True, **kws)]\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36mlist_collections\u001b[0;34m(self, session, filter, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         return self.__client._retryable_read(\n\u001b[0;32m--> 819\u001b[0;31m             _cmd, read_pref, session)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_collection_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_read\u001b[0;34m(self, func, read_pref, session, address, retryable, exhaust)\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m                 server = self._select_server(\n\u001b[0;32m-> 1455\u001b[0;31m                     read_pref, session, address=address)\n\u001b[0m\u001b[1;32m   1456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretryable_reads_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m                     \u001b[0mretryable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_select_server\u001b[0;34m(self, server_selector, session, address)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                                         % address)\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 \u001b[0;31m# Pin this session to the selected server if it's performing a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                 \u001b[0;31m# sharded transaction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    229\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    230\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             server_descriptions = self._select_servers_loop(\n\u001b[0;32m--> 189\u001b[0;31m                 selector, server_timeout, address)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             return [self.get_server_by_address(sd.address)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 205\u001b[0;31m                     self._error_message(selector))\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "collection = db['Hola']\n",
    "db.collection_names()\n",
    "#Empty collections do not show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: database_names is deprecated. Use list_database_names instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aa6f68719a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The database has a collection, thus ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36mdatabase_names\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         warnings.warn(\"database_names is deprecated. Use list_database_names \"\n\u001b[1;32m   1923\u001b[0m                       \"instead.\", DeprecationWarning, stacklevel=2)\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_database_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_database\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36mlist_database_names\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \"\"\"\n\u001b[1;32m   1905\u001b[0m         return [doc[\"name\"]\n\u001b[0;32m-> 1906\u001b[0;31m                 for doc in self.list_databases(session, nameOnly=True)]\n\u001b[0m\u001b[1;32m   1907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdatabase_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36mlist_databases\u001b[0;34m(self, session, **kwargs)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0madmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_database_default_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"admin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retryable_read_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m         \u001b[0;31m# listDatabases doesn't return a cursor (yet). Fake one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         cursor = {\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36m_retryable_read_command\u001b[0;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         return self.__client._retryable_read(\n\u001b[0;32m--> 749\u001b[0;31m             _cmd, read_preference, session)\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     def _list_collections(self, sock_info, slave_okay, session,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_retryable_read\u001b[0;34m(self, func, read_pref, session, address, retryable, exhaust)\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m                 server = self._select_server(\n\u001b[0;32m-> 1455\u001b[0;31m                     read_pref, session, address=address)\n\u001b[0m\u001b[1;32m   1456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretryable_reads_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m                     \u001b[0mretryable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_select_server\u001b[0;34m(self, server_selector, session, address)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                                         % address)\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 \u001b[0;31m# Pin this session to the selected server if it's performing a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                 \u001b[0;31m# sharded transaction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    229\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    230\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             server_descriptions = self._select_servers_loop(\n\u001b[0;32m--> 189\u001b[0;31m                 selector, server_timeout, address)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             return [self.get_server_by_address(sd.address)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 205\u001b[0;31m                     self._error_message(selector))\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "#The database has a collection, thus ...\n",
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB stores structured data as JSON-like (JavaScript Object Notation) documents, using dynamic schemas (called BSON), rather than predefined schemas. An element of data is called a document, and documents are stored in collections. One collection may have any number of documents.\n",
    "\n",
    "Compared to relational databases, we could say collections are like tables, and documents are like records. But there is one big difference: every record in a table has the same fields (with, usually, differing values) in the same order, while each document in a collection can have completely different fields from the other documents.\n",
    "\n",
    "All you really need to know when you're using Python, however, is that documents are Python dictionaries that can have strings as keys and can contain various primitive types (int, float,unicode, datetime) as well as other documents (Python dicts) and arrays (Python lists).\n",
    "\n",
    "To insert some data into MongoDB, all we need to do is create a dict and call .insert() on the collection object. Let us exemplify this process by downloading an url and storing it in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import time\n",
    "# dd/mm/yyyy format\n",
    "print (time.strftime(\"%d/%m/%Y\"))\n",
    "url = 'http://www.ub.edu/datascience/postgraduate/'\n",
    "html = urlopen(url).read().decode('latin-1')\n",
    "\n",
    "#Create a dictionary/document to store\n",
    "doc = {}\n",
    "doc['url'] = url\n",
    "doc['date'] = time.strftime(\"%d/%m/%Y\")\n",
    "doc['html'] = html\n",
    "doc['adios'] = 'esto es otra prueba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the document in the collection\n",
    "collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that we have a non empty collection.\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we have databases containing collections. A collection is made up of documents. Each document is made up of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.find_one() #Returns one random document in the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more than a single document as the result of a query we use the find() method. find() returns a Cursor instance, which allows us to iterate over all matching documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in collection.find():\n",
    "    try:\n",
    "        print (d['adios'])\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to know how many documents match a query we can perform a count() operation instead of a full query. We can get a count of all of the documents in a collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying in pymongo uses .find() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in collection.find({\"hola\":\"esto es otra prueba\"}):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that it finds exact matches. Operations include *gt* (greater than), *gte* (greater than equal), *lt* (lesser than), *lte* (lesser than equal), *ne* (not equal), *nin* (not in a list), *regex* (regular expression), *exists*, *not*, *or*, *and*, etc. Let us see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.find({\"date\":{\"$gte\":\"01/01/2014\"}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substring = \"datascience\"\n",
    "reg = substring\n",
    "collection.find({\"html\":{\"$regex\":reg}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in collection.find({\"html\":{\"$regex\":\"datascience\"}}):\n",
    "    print (item['html'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short practical introduction to RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have come across RegEx a couple of times now. So we better give a short pragmatical introduction to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<ul>\n",
    "    <li> Regular expressions are pattern matching rules. In essence everything is a character and the regular expression are a set of rules of the character patterns to seek.</li>\n",
    "    <li> If we provide a raw set of characters it will look for exact matches, e.g. 'aBc1' </li>\n",
    "    <li> There are wildcards: . (matches any character), *\\d* (matches any digit), *\\w* (matches any alphanumeric character), *\\s* (any whitespace such as space, new line, carrier return, tab, etc.)</li>\n",
    "    <li>An interesting metacharacter is *\\b* that stands for boundary and matches the boundary between a word character and a non-word character.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Match the three strings\n",
    "ex1 = 'abc abcde Abcdefg bcde'\n",
    "\n",
    "pattern = re.compile('[aA]bc')\n",
    "print(re.findall(pattern,ex1))\n",
    "\n",
    "ex2 = 'abc123xyz define123 var g = 123'\n",
    "pattern = re.compile('123')\n",
    "for m in re.finditer(pattern, ex2):\n",
    "    print ('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<ul>\n",
    "    <li> Capital letters denote the negation of the concept, i.e. *\\D* is everything except digits, *\\W* everything expect alphanumeric chars (e.g. puntuation marks, etc), *\\S* any non-spacing character.</li>\n",
    "    <li>Repetitions of a character can be handled explicitly using curly brackets, e.g. *a{3}* means three repetitions of character \"a\"</li>\n",
    "    <li>Undefinite number of values are given by star and plus signs (\\* and +). Star will match 0 to infty number of times and Plus will do it one or more times, e.g. .* will stand for any amount of any character</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all adverbs (words ended by ly)\n",
    "import re\n",
    "text = \"He was carefully disguised but captured quickly by police.\"\n",
    "for m in re.finditer(r\"\\w+ly\", text):\n",
    "    print ('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<ul>\n",
    "     <li>Optional values can be given by the question mark sign. The preceding character will be optional, e.g. cats? stands for cat and cats.</li>\n",
    "     <li>Another way of checking for specific options is to use square brackets. For example *[abc]* will match only a, b, or c.</li>\n",
    "     <li>We can negate a set in square brackets *[^abc]*</li>\n",
    "     <li>We can select ranges, such as *[a-z]*, *[A-Z]* or *[0-9]*</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the names of the first two items without extension\n",
    "#All of them start with file, thus it is a boundary and \"file pattern\", then any amount of arbirtary characters wil do and finally it will end with .pdf\n",
    "import re\n",
    "text = 'file_a_record_file.pdf file_yesterday.pdf testfile_fake.pdf.tmp' \n",
    "for m in re.finditer(r\"\\bfile\\w*\\.pdf\", text):\n",
    "    print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trim starting and ending spaces\n",
    "\n",
    "text = \"               Masters of Ba Gua Zhang    \"\n",
    "\n",
    "for m in re.finditer(r\"\\s*(.+)\\s*$\", text):\n",
    "    print ('%02d-%02d: %s' % (m.start(1), m.end(1), m.group(1))) #Note that we use group(1), group(0) is the complete match without capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<ul>\n",
    "     <li>Another interesting feature is capturing. In parenthesis we can define the group or set of data we want to return. In python we can access these data by indexing the match. At the first position we will get the first capture, in the second position the nested capture or group, etc.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens if we change index 1 for index 0 in the former example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match the numbers and skip the last item\n",
    "text = '3.1452 -255.34 128 1.9e10 123,34.00 720p'\n",
    "\n",
    "for m in re.finditer(r\"-?\\d+[\\.,]?\\d*[\\.e]?\\d*\\b\", text):\n",
    "    print ('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the links in a html page\n",
    "from urllib.request import urlopen\n",
    "url = 'http://www.ub.edu/'\n",
    "html = urlopen(url).read().decode()\n",
    "\n",
    "\n",
    "for m in re.finditer(r\"href=\\\"(\\S+)\\\"\", html):\n",
    "    print ('%02d-%02d: %s' % (m.start(1), m.end(1), m.group(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are usually not the answer due to the fragility of html pages on the internet today -- common mistakes like missing end tags, mismatched tags, forgetting to close an attribute quote, would all derail a perfectly good regular expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, several methods for updating and deleting documents are reveiwed:\n",
    "\n",
    "+ Update. This method finds the documents defined by query and **replaces** it by the new document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import time\n",
    "# dd/mm/yyyy format\n",
    "print (time.strftime(\"%d/%m/%Y\"))\n",
    "url = 'http://www.ub.edu/datascience'\n",
    "html = urlopen(url).read()\n",
    "\n",
    "#Create a dictionary/document to store\n",
    "doc = {}\n",
    "doc['url'] = url\n",
    "doc['date'] = time.strftime(\"%d/%m/%Y\")\n",
    "doc['html'] = html\n",
    "doc['foo'] = 'foo'\n",
    "\n",
    "import pymongo\n",
    "conn = pymongo.MongoClient()\n",
    "conn.database_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = conn.test\n",
    "collection = db.coltest\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update_one({'url':{'$regex':'datascience'}},{\"$set\":{'html':'mola'}},upsert=True)\n",
    "\n",
    "for doc in collection.find_one():\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost all the document and replaced it by the new instance that only has the 'html' key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the behavior of the update command by adding a sub-command. Let us check some of them:\n",
    "\n",
    "+ Sub-command **Set**:\n",
    "\n",
    "This statement updates in the document in collection where field matches value1 by replacing the value of the field field1 with value2. This operator will add the specified field or fields if they do not exist in this document or replace the existing value of the specified field(s) if they already exist.\n",
    "\n",
    "An upsert eliminates the need to perform a separate database call to check for the existence of a record before performing either an update or an insert operation. Typically update operations update existing documents, but in MongoDB, the update() operation can accept an upsert option as an argument. Upserts are a hybrid operation that use the query argument to determine the write operation:\n",
    "\n",
    "If the query matches an existing document(s), the upsert performs an update.\n",
    "If the query matches no document in the collection, the upsert inserts a single document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update_one({\"html\":\"mola\"},{\"$set\":{\"html\":\"new data\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update_many({\"html\":\"new date\"},{\"$set\":{\"html\":\"modify\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing changes since there is no match for the query. Let us use upsert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update_many({\"html\":\"new date\"},{\"$set\":{\"html\":\"modify\"}}, upsert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Sub-commnad **Unset**:\n",
    "\n",
    "The unset operator deletes a particular field. If documents match the initial query but do not have the field specified in the unset operation, there the statement has no effect on the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update_many({\"html\":\"modify\"},{\"$unset\":{\"html\":\"\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several update commands that work with lists allowing to remove the first element (pop), any amount of elements (pull) or insert an element (push).\n",
    "\n",
    "By the way, the dollar character used at the before the command identifies an element in an array field to update without explicitly specifying the position of the element in the array.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove elements by simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete_one({\"html\":\"new data\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remove a collection by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_collection(\"coltest\")\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remove a database by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.drop_database('test')\n",
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally close the connection with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Finishing the warm up project with MongoDB storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import time\n",
    "#Import pymongo\n",
    "import pymongo\n",
    "\n",
    "\n",
    "def getLinks(html, max_links=10):\n",
    "    url = []\n",
    "    cursor = 0\n",
    "    nlinks=0\n",
    "    while (cursor>=0 and nlinks<max_links):\n",
    "        start_link = html.find(\"a href\",cursor)\n",
    "        if start_link==-1:\n",
    "            return url\n",
    "        start_quote = html.find('\"', start_link)\n",
    "        end_quote = html.find('\"', start_quote + 1)\n",
    "        url.append(html[start_quote + 1: end_quote])\n",
    "        cursor = end_quote+1\n",
    "        nlinks = nlinks +1\n",
    "    return url\n",
    "\n",
    "class Spider:\n",
    "    def __init__(self,starting_url,crawl_domain,max_iter):\n",
    "        self.crawl_domain = crawl_domain\n",
    "        self.max_iter = max_iter\n",
    "        self.links_to_crawl=[]\n",
    "        self.links_to_crawl.append(starting_url)\n",
    "        self.links_visited=[]\n",
    "        self.collection=[]\n",
    "        # Create the connection to MongoDB\n",
    "        try:\n",
    "            self.conn=pymongo.MongoClient()\n",
    "            print (\"Connection to Mongo Daemon successful!!!\")\n",
    "        except pymongo.errors.ConnectionFailure as e:\n",
    "            print (\"Could not connect to MongoDB: %s\" % e )\n",
    "        self.db = conn['crawlerDB']\n",
    "        self.collection = self.db[starting_url+'DB']\n",
    "\n",
    "        \n",
    "    def retrieveHtml(self):\n",
    "        try:\n",
    "            socket = urlopen(self.url);\n",
    "            self.html = socket.read().decode('latin-1')\n",
    "            return 0\n",
    "        except HTTPError:\n",
    "            # Most probably an url not found 404, possibly due to malformating of the links in retrieveAndValidateLinks\n",
    "            return -1\n",
    "             \n",
    "    def run(self):\n",
    "        #Change the count on the collection\n",
    "        while (len(self.links_to_crawl)>0 and self.collection.count()<self.max_iter):\n",
    "            self.url = self.links_to_crawl.pop(0)\n",
    "            print (self.links_to_crawl)\n",
    "            self.links_visited.append(self.url)\n",
    "            if self.retrieveHtml()>=0:\n",
    "                self.storeHtml()\n",
    "                self.retrieveAndValidateLinks()\n",
    "        self.conn.close()\n",
    "    \n",
    "    def retrieveAndValidateLinks(self):\n",
    "        tmpList=[]\n",
    "        items = getLinks(self.html,max_links=50)\n",
    "        # Check the validity of a link\n",
    "        for item in items:\n",
    "            item = item.strip('\"')\n",
    "            if '.pdf' not in item:\n",
    "                if self.crawl_domain in item:\n",
    "                    tmpList.append(item)\n",
    "                else:\n",
    "                    if not(\":\") in item: #Take care of http:// https:// and mailto:\n",
    "                        tmpList.append(self.crawl_domain+item)\n",
    "        # Check that the link has not been previously retrieved or is currently on the links_to_crawl list\n",
    "        for item in tmpList:\n",
    "            if item not in self.links_visited:\n",
    "                if item not in self.links_to_crawl:\n",
    "                    self.links_to_crawl.append(item)\n",
    "                    print ('Adding: '+item)\n",
    "                \n",
    "    def storeHtml(self):\n",
    "        doc = {}\n",
    "        doc['url'] = self.url\n",
    "        doc['date'] = time.strftime(\"%d/%m/%Y\")\n",
    "        doc['html'] = self.html\n",
    "        #Insert in the collection\n",
    "        self.collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider = Spider('http://hunch.net','http://hunch.net/',20)\n",
    "spider.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymongo.MongoClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (conn.database_names())\n",
    "db = conn['crawlerDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.collection_names()\n",
    "db.drop_collection(\"http://hunch.netDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db['http://hunch.netDB']\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc['url'])\n",
    "    print (doc['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "**PROS and CONS:**\n",
    "<p>\n",
    "**MongoDB** querying is powerful but based on basic string operations. This actually tells us that storing full HTML pages is not going to be effiecient for retrieval. Actually, we will see that it is important to break the information in the pieces we really want. However, this is a good starting point before a post processing if we are not sure what we are going to do with the data or further scraping is going to take long. </p>\n",
    "</div>\n",
    "\n",
    "In the next section we will see more efficient ways of dealing with web based data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "**URLLIB** is good for getting simple things. In the end you end up with a large HTML string you want to do something on it. \n",
    "So the next thing you want to do is to parse data. But you want to do it in the same way you do when you interact with the web page. You see a menu, a frame on the left side, a nice colorful block where the price for your flight is. So **you want to parse data the way you see data in the webpage so that you can target it**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the API\n",
    "\n",
    "Recall the **big picture**. If we are targeting for specific data we could check if the web site has a programatic interface for querying. If it has we can use it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"border-radius:20px;\" src=\"./files/big_picture.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping twitter data with the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard way for programatically communicating with a web service is using the API (Application Programing Interface) whenever it is provided. Twitter provides several APIs. The two most important ones are the RESTful API for static queries (e.g. user's friends and followers, check timelines, etc) and the Streaming API for retrieving live data. The REST API identifies Twitter applications and users using OAuth; responses are available in JSON. The Streaming API should not need authentication.\n",
    "\n",
    "Ex. \n",
    "\n",
    "https://api.twitter.com/oauth/authenticate?oauth_token=XXXXXXXXXXXXXX\n",
    "\n",
    "https://api.twitter.com/1.1/followers/ids.json?cursor=-1&screen_name=my_user_name&count=5000\n",
    "\n",
    "Building these queries is not always easy, thus we may use a wrapper around the API. This is what **tweepy** does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the API with authentification (needed for the RESTful API)\n",
    "\n",
    "From wikipedia:\n",
    "\n",
    ">\"Web service APIs that adhere to the architectural constraints are called RESTful. HTTP based RESTful APIs are defined with these aspects:\n",
    "\n",
    "> <ul><li>base URI (Uniform Resource Identifier), such as http://example.com/resources/\n",
    "<li>an Internet media type for the data. This is often JSON but can be any other valid Internet media type (e.g. XML, Atom, microformats, images, etc.)</li>\n",
    "<li>standard HTTP methods (e.g., GET [retrieve], PUT[idempotent update/create], POST[update/create], or DELETE)</li>\n",
    "<li>hypertext links to reference state</li>\n",
    "<li>hypertext links to reference related resources\"</li>\n",
    "</ul>\n",
    "\n",
    "If we want to use the RESTful API in Twitter we have to follow these steps:\n",
    "<ul>\n",
    "<li>From your twitter account we want to generate a token: https://apps.twitter.com</li>\n",
    "<li>Create a new App. This will create the API keys (consumer keys)</li>\n",
    "<li>Go to API Keys and generate a token. (access keys)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import tweepy\n",
    "\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "access_key = \"\"\n",
    "access_secret = \"\"\n",
    "\n",
    "#Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Do something\n",
    "USER_NAME = \"espavilat\"\n",
    "user = api.get_user(id=USER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access some basic information about the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.friends_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.followers_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">JSON (JavaScript Object Notation), is an open standard format that uses human-readable text to transmit data objects consisting of attribute–value pairs. It is used primarily to transmit data between a server and web application, as an alternative to XML. JSON is a way to encode complicated information in a platform-independent way.  It could be considered the lingua franca of information exchange on the Internet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can access the full JSON\n",
    "user._json['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access all the information as it was a dictionary structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juser = user._json\n",
    "print (juser['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply our basic scrape knowledge and use urllib2 to retrieve more interesting infomation, such as the profile image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = juser['profile_image_url']\n",
    "print (img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "f = open('scraped_image','wb')\n",
    "f.write(urlopen(img_url).read())\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "im=plt.imread('scraped_image')\n",
    "plt.imshow(im,interpolation='nearest')\n",
    "plt.title(juser['screen_name'],size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to retrieve the list of follower ids. There are two ways for doing so. Both uses the `api.followers_ids` function. The function returns a maximum of 100 ids. If we want to get all of them we may use a pagination variable `cursor`. This can be managed directly in the call `api.followers_ids(id, cursor)` or using a `Cursor` object with the `pages` method that handles the cursor implicitly. This second method is illustrated in the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving all the followers\n",
    "ids = []\n",
    "for page in tweepy.Cursor(api.followers_ids, screen_name=USER_NAME).pages():\n",
    "    ids.extend(page)\n",
    "    time.sleep(20)  #This should be 60 to avoid limit rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `sleep` command. This is needed to respect the hourly limit rates of the Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#friends (screen_name) or follower_ids\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document={}\n",
    "document['user'] = user.id\n",
    "document['followers'] = ids[:]\n",
    "\n",
    "# Create the connection to MongoDB\n",
    "try:\n",
    "    conn=pymongo.MongoClient()\n",
    "    print (\"Connection to Mongo Daemon successful!!!\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e )\n",
    "db = conn['twitter']\n",
    "collection = db['twitter_users']\n",
    "collection.insert_one(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc['followers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:16px;\"> **TAKE HOME EXERCISE:** Given a starting user ID, retrieve the user ids corresponding to the set of followers up to two depth levels. This is the followers of the followers of the named user. This information creates a network of influence that will be used in upcoming sessions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Streaming API** works by making a request for a specific type of data — filtered by keyword, user, geographic area, or a random sample — and then keeping the connection open as long as there are no errors in the connection. The data you get back will be encoded in JSON. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main usage cases of tweepy is monitoring for tweets and doing actions when some event happens. Key component of that is the StreamListener object, which monitors tweets in real time and catches them.\n",
    "\n",
    "If we check the official twitter streaming API we see that we have several modifiers for filtering the stream, i.e. track (filter by keyword), locations (filter by geographic location), etc\n",
    "\n",
    "StreamListener has several methods, with on_data() and on_status() being the most useful ones. Here is a sample program which implements this behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream,StreamListener\n",
    "\n",
    "class listener(StreamListener):\n",
    "    def on_data(self, data):\n",
    "        #Beauty print data\n",
    "        parsed = json.loads(data)\n",
    "        print (json.dumps(parsed, indent=4, sort_keys=True))\n",
    "        return True\n",
    "    def on_error(self, status):\n",
    "        print ('ERROR')\n",
    "        print (status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the twitter data filtered by location inside the following bounding box. (http://boundingbox.klokantech.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style = \"border-radius:10px;\" src=\"./files/ub_location.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterStream = Stream(auth, listener()) \n",
    "twitterStream.filter(locations=[2.1622322352,41.385987385,2.1651827408,41.3877173586])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other examples\n",
    "twitterStream = Stream(auth, listener()) \n",
    "#twitterStream.filter(track=[\"datascience\"])\n",
    "#Use http://boundingbox.klokantech.com to get the Barcelona bounding box\n",
    "twitterStream.filter(locations=[2.0504377635,41.2787636541,2.3045074059,41.4725622346])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tweepy import Stream,StreamListener\n",
    "\n",
    "class listener(StreamListener):\n",
    "    def on_data(self, status):\n",
    "        json_data=json.loads(status)\n",
    "        print (str(json_data[\"user\"][\"screen_name\"])+' : ' + json_data[\"text\"])\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print ('Error')\n",
    "        print (status)\n",
    "        \n",
    "# Catch all tweets in Barcelona area and print them\n",
    "twitterStream = Stream(auth, listener()) \n",
    "#twitterStream.filter(locations=[2.1622322352,41.385987385,2.1651827408,41.3877173586])\n",
    "twitterStream.filter(locations=[2.0504377635,41.2787636541,2.3045074059,41.4725622346])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fill the class in order to capture and store the data in a MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream,StreamListener\n",
    "\n",
    "class listener(StreamListener):\n",
    "    def __init__(self):\n",
    "        super(StreamListener, self).__init__()\n",
    "        try:\n",
    "            self.conn=pymongo.MongoClient()\n",
    "            print (\"Connection to Mongo Daemon successful!!!\")\n",
    "        except pymongo.errors.ConnectionFailure as e:\n",
    "            print (\"Could not connect to MongoDB: %s\" % e )\n",
    "        self.db = conn['twitter_stream']\n",
    "        self.collection = db['tweets']\n",
    "    \n",
    "    def on_data(self, status):\n",
    "        jdata = json.loads(status)\n",
    "        if 'android' in jdata[\"source\"]:\n",
    "            device = \"android\"\n",
    "        else:\n",
    "            device = \"apple\"\n",
    "        document={'text':jdata[\"text\"], 'created':jdata[\"created_at\"], 'screen_name':jdata[\"user\"][\"screen_name\"], 'device':device}        \n",
    "        self.collection.insert(document) \n",
    "        print (document)\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print ('ERROR')\n",
    "        print (status)\n",
    "\n",
    "# Catch all tweets in Barcelona area and print them\n",
    "twitterStream = Stream(auth, listener()) \n",
    "twitterStream.filter(locations=[2.0504377635,41.2787636541,2.3045074059,41.4725622346])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check captured data\n",
    "try:\n",
    "    conn=pymongo.MongoClient()\n",
    "    print (\"Connection to Mongo Daemon successful!!!\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e )\n",
    "\n",
    "db = conn['twitter_stream']\n",
    "collection = db['tweets']\n",
    "collection.count()\n",
    "for doc in coll.find():\n",
    "    print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.database_names()\n",
    "db = conn['twitter']\n",
    "coll = db.tweets\n",
    "for item in coll.find():\n",
    "    print (item['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIs are nice. Most large web site provide useful APIs, e.g. Google, OpenStreetMap, Facebook, etc, subject to some use terms. However most of the web sited do not provide any kind of access to data. What to do then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making your own API: Web scraping\n",
    "\n",
    "Sometimes data is on the web but there is no API to grant access to it, the API is lacking functionalities or the terms of service are not adequate. In those cases because as humans we have visual access to the data we might wonder how to extract that data automatically. The discipline for doing so is **Web Scraping**. \n",
    "\n",
    "Before we start, it is useful to understand a little how web pages are created and data stored. In this section a brief introduction to web front-end development is presented. We will focus on two basic aspects:\n",
    "\n",
    "+ Basic HTML + CSS static pages.\n",
    "+ Dynamic HTML (a basic JavaScript example using JQuery).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "**Firebug example on a page.**\n",
    "\n",
    "Go to a page and check its contents using Inspect Element\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic HTML + CSS 101\n",
    "\n",
    "The most basic web pages are built upon HTML + CSS technology. This division stnds for content and design, respectively. **HTML (Hypertext markup language)** is used to give websites structure and stores the contents. This is our target for scraping. On the other hand **CSS (Cascading Style Sheets)** gives format to the content, sigles out content for visualization purposes, i.e. defines the style (e.g. font, color, family, borders, image style, relative positioning of the content, etc). HTML files include tags and references to style, thus it is worthwhile to understand a little bit of both technologies which can help us to scrap data more efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML is a tagged language usually rendered by a browser. Tags are specified in the following format:\n",
    "\n",
    "<p style=\"text-align: center\">&lt;tag_name *attributes*&gt; content &lt;/tag_name&gt;<p>\n",
    "\n",
    "<p>\n",
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">STRUCTURE of an HTML file:\n",
    "\n",
    "<ul>\n",
    "    <li> HTML files start with the <!DOCTYPE html>. This tells the browser that we will use HTML5. In former versions of HTML standard there were different versions. </li>\n",
    "    <li> The first tag in a web page is &lt;html&gt; and its corresponding &lt;/html&gt; closing tag. All the web page is found inside these tags. </li>\n",
    "    <li> HTML files have a &lt;head&gt; and a &lt;body&gt; </li>\n",
    "    <li> In the head, we have the &lt;title&gt; tags, and we use this to specify the webpage's name. We can also find references to CSS stylesheets (&lt;link&gt;) used for formating the page and links to javascript files (&lt;script&gt;)that give the web page dynamic behavior.</li>\n",
    "    <li> In the body we find the content of the page. </li> \n",
    "        <ul>\n",
    "            <li> Headings and text paragraphs can be created using &lt;h#&gt; (# is a natural number) and &lt;p&gt; ,respectively. </li>\n",
    "            <li> Hyperlinks (links) are given in the <strong>href</strong> attribute of the &lt;a&gt; (anchor) tag. </li>\n",
    "            <li> Images can be embedded using the &lt;img&gt; tag and setting the <strong>src</strong> attribute to the resource. Caution: img is an special tag and it does not have a closing tag, e.g. &lt;img src = \"my_pic.jpg\" /&gt; </li>\n",
    "        </ul>\n",
    "</ul>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE**\n",
    "\n",
    "Let us build a basic HTML web page, adding the following tags. Remember that nearly all tags require to be closed using &lt;/tag&gt;\n",
    "\n",
    "+ DOCTYPE\n",
    "+ html\n",
    "+ head\n",
    "+ title\n",
    "+ body\n",
    "\n",
    "<ol>\n",
    "<li>Create a file 'example.html' in your favorite editor.</li>\n",
    "<li>Create a basic html web page containing a *title*, *h1*, *p*, *img* and *a* tags.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are lazy go to the files folder and double-click on \"example.html\". You can check the html code executing the following line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>\n",
    "\t\t\tBasic knowledge for web scraping.\n",
    "\t\t</title>\t\n",
    "\t</head>\n",
    "\t<body>\n",
    "\t\t<h1>About HTML\n",
    "\t\t</h1>\n",
    "\t\t<p>Html (Hypertext markdown language) is the basic language to provide contents in the web. It is a tagged language. You can check more about it in <a href=\"http://www.w3.org/community/webed/wiki/HTML\">World Wide Web Consortium.</a></p>\n",
    "        \n",
    "        <p> One of the following rubberduckies is clickable\n",
    "\t</p>\n",
    "\t<p>\n",
    "            <img src = \"files/rubberduck.jpg\"/>\n",
    "        \n",
    "            <a href=\"http://www.pinterest.com/misscannabliss/rubber-duck-mania/\"><img src = \"files/rubberduck.jpg\"/></a>\n",
    "        </p>\n",
    "\t</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>\n",
    "\t\t\tBasic knowledge for web scraping.\n",
    "\t\t</title>\t\n",
    "\t</head>\n",
    "\t<body>\n",
    "\t\t<h1>About HTML\n",
    "\t\t</h1>\n",
    "\t\t<p>Html (Hypertext markdown language) is the basic language to provide contents in the web. It is a tagged language. You can check more about it in <a href=\"http://www.w3.org/community/webed/wiki/HTML\">World Wide Web Consortium.</a></p>\n",
    "        \n",
    "        <p> One of the following rubberduckies is clickable\n",
    "\t</p>\n",
    "\t<p>\n",
    "            <img src = \"files/rubberduck.jpg\"/>\n",
    "        \n",
    "            <a href=\"http://www.pinterest.com/misscannabliss/rubber-duck-mania/\"><img src = \"files/rubberduck.jpg\"/></a>\n",
    "        </p>\n",
    "\t</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Ipython notebook cells directly interpret markdown and HTML we can use the cell as an interactive editor for our HTML understanding.\n",
    "<div class  = \"alert alert-success\">** EXERCISE ** <p>\n",
    "Change the type of cell of the former cell to *Markdown* and Execute (SHIFT+ENTER). In order for the files to show you must add the relative path to the image, e.g. ./files/rubberduck.jpg\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "**Old style HTML** static pages rely heavily on tables and lists: \n",
    "\n",
    "<ul>\n",
    "<li> Making ordered and unordered lists is simple: *ol* (ordered list), *ul* (unordered list) are the main tags. Each item is inserted as *li* (list item) </li>\n",
    "<li> *table* is the containing tag for building tables, each table row is given as *tr* and columns depend on the table data elements *td*. Tables may have a head (*thead*) and a body (*tbody*). *th* is the same as *td* but for the header. If you want a multi column cell then use colspan=number of cells to cover.\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example shows a simple table build. Check the markdown code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th colspan = 2>A table</th><tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Hello I am element 1.1</td><td>Hello I am element 1.2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=2>Hello I am element 2.1 and 2.2</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "**Current HTML** static pages rely heavily on containers and style: \n",
    "\n",
    "<ul>\n",
    "<li> *div* stands for division and mark a block of content.\n",
    "</li>\n",
    "<li> *span* is used to single out an element of a block content.\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "</div>\n",
    "\n",
    "By themselves they are not much but when combined with the *style* attribute they become interesting.\n",
    "\n",
    "For example, consider the following example of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"width:100px;height:100px;background-color:red;padding:10px;font-family:Verdana;font-size:24;color:pink;display:inline-block\">  Box 1\n",
    "</div>\n",
    "<div style = \"width:100px;height:100px;background-color:blue;padding:10px;font-family:Futura;font-size:24;color:lightblue;display:inline-block\">  Box 2\n",
    "</div>\n",
    "<div style = \"width:100px;height:100px;background-color:yellow;padding:10px;font-family:Garamond;font-size:24;color:orange;display:inline-block\">  Box 3\n",
    "</div>\n",
    "<div style = \"width:100px;height:100px;background-color:green;padding:10px;font-family:ArialNarrow;font-size:24;color:lightgreen;display:inline-block\">  Box 4\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute *style* is also referred as *inline CSS* and let us give the skeleton some skin and makeup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE**\n",
    "\n",
    "Let us build a basic HTML web page and check the magic of CSS in action before going in detail into CSS.\n",
    "<ol>\n",
    "<li>Create a file 'example2.html' using your favorite editor.</li>\n",
    "<li>Fill the header and body basic HTML structure</li>\n",
    "<li>Let us add three containers *div* in the body.</li> \n",
    "<li>Select one of them. This will be used as a navigation bar and will contain an unordered list with three elememnts: Home, Brief Bio, Hobbies</li>\n",
    "<li>Select another division and create a table inside. Each row will contain information about your profile, e.g. the first row may contain Name: Your Name, the second row Position: Your current position, etc</li>\n",
    "<li>The last one will contain an image of youself and a paragraph with your contact info (email)</li>\n",
    "</ol>\n",
    "<p>\n",
    "Check the result. Nearly professional, doesn't it?\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE FOLLOW UP**\n",
    "\n",
    "Let us add some style.\n",
    "<ol>\n",
    "<li>Add the class \"navbar\" as an attribute to the *div* containing the list. (eg. class = \"navbar\")</li>\n",
    "<li>Add the class \"head\" to the *div* containing the image and the email.</li>\n",
    "<li>Add the class \"right\" to the *div* containing the table.</li>\n",
    "<li>Add the identifier \"email\" to the paragraph containing the email. (eg. id = \"email\")</li>\n",
    "<li>Finally, let us link the class and ids definitions we have just writen by adding to the head tag the following line:\n",
    "<p>< link type=\"text/css\" rel=\"stylesheet\" href=\"stylesheet.css\"/ ></p>\n",
    "</li>\n",
    "</ol>\n",
    "<p>\n",
    "Check the result now. Do not forget to hover over your navigation bar.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The former exercise is an extremely simple exercise showing the separation between the content and the styling. Observe that the html file you have created does not have any explicit styling. However, we have added two new elements to the mix, classes and identifiers as attributes of the tags. As you can imagine styling rules are given for each class and ID and are compactly found on the stylesheet.css we have just linked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style = \"border-radius:10px;border-width:3px;border-color:orange;font-family:Verdana,sans-serif;font-size:16px;\">**COMMENT:**\n",
    "Very simple formating can be also given using html markers. For example *strong* and *em* tags refers to bold and italics fonts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSS (which stands for Cascading Style Sheets)** is a language used to describe the appearance and formatting of your HTML. A style sheet is a file that describes how an HTML file should look. The word cascading refers to the fact that a specific style rules override more generic ones. We will see that in a minute. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">FORMAT of a CSS file:\n",
    "\n",
    "<ul>\n",
    "    <li> CSS files contains a set of style rules applied to a certain selection of the content of the html file. The format is as follows:\n",
    "    \n",
    "    <p style = \"font-family:Courier;margin-left:200px;\"> css_selector { \n",
    "                property: value;\n",
    "        }\n",
    "    </p>\n",
    "    and may contain many properties.\n",
    "    \n",
    "    <li> <span style = \"font-family:Courier\"> css_selector </span> identifies a certain context of the Document Object Model (DOM), i.e. it allows to traverse the DOM and select specific blocks. For example, \n",
    "    <p style = \"font-family:Courier;margin-left:200px;\">\n",
    "        div { color:red; }\n",
    "    </p>\n",
    "    selects all *div* tags and apply a red font color to their content.\n",
    "    </li>\n",
    "    <li> We can use any html tag as element for selection.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "    **CLASSES:**\n",
    "        <ul>\n",
    "        <li> We may link/format a certain set of tags of the html file with a unique CSS style by means of a **class**. </li>\n",
    "        <li> In html the class is defined as an attribute and can be shared among tags, e.g. < div class = \"my_class\" > and < p class = \"my_class\">\n",
    "        </li>\n",
    "        <li> In the css file, the class is identified with a point preceeding the name, e.g.\n",
    "         <p style = \"font-family:Courier;margin-left:200px;\">\n",
    "            .my_class { font-family:Verdana; }\n",
    "        </p>\n",
    "        </li>\n",
    "        </ul>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "    **IDENTIFIERS:**\n",
    "        <ul>\n",
    "        <li> If we want to single out an element to apply a certain style we can use an **identifier**. </li>\n",
    "        <li> In html the identifier is defined as the attribute **ID**, e.g. < div id = \"my_ID\" >\n",
    "        </li>\n",
    "        <li> In the css file, the identifier name is preceeded by a hash sign (#), e.g.\n",
    "         <p style = \"font-family:Courier;margin-left:200px;\">\n",
    "            #my_ID { font-size:24px; }\n",
    "        </p>\n",
    "        </li>\n",
    "        </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE**\n",
    "\n",
    "Check stylesheet.css and inspect the formating of the identifiers and the classes.\n",
    "<ol>\n",
    "<li>\n",
    "Create an identifier name_props that changes the font-family to Courier.\n",
    "</li>\n",
    "<li>\n",
    "Add this identifier to the *td* tag with your name in the profile.\n",
    "</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE**\n",
    "\n",
    "Let us make our own css style sheet and explore a little of the more advanced CSS selectors.\n",
    "<ol>\n",
    "<li>Create a file 'mystylesheet.css' using your favorite editor and open example3.html in your browser.</li>\n",
    "<li>What happens if we add the following style command? \n",
    "<p style=\"font-family:Courier\">div {font-family:Verdana;font-size:16px;}</p></li>\n",
    "<li>Add the following line in the style sheet:\n",
    "<p style=\"font-family:Courier\">div div{color:red;}</p></li>\n",
    "<li>Add the following line in the style sheet:\n",
    "<p style=\"font-family:Courier\">div>div{color:green;}</p></li>\n",
    "<li>Add the style to make the font of the container regarding Bruce Lee comments on Choy Li Fut have *font-size:14px*, *font-family:Courier*, *background-color:#FFCC66;*, and *color:yellow*.\n",
    "<li>Add a style to the *img* tag with *height* of *230px* and *width* of *200px*. Set the width of the table to 700 pixels width.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last exercise we have seen another type of css selection. The html document can be seen as a tree structure. The root of the tree is the *html* tag. This has two children *head* and *body*. Head may have different children such as *title*, *link*, or *script*. Body may have any combination of tags, *divs*, *p*, *a*, etc. These tags can be nested, e.g. we can find a *div* inside a *div* inside a *div*. In the example we have seen how to refer to nested elements. The elements can be html tags or classes or identifiers.\n",
    "    + \"elem1 elem2\" refers to any elem2 inside any other elem1 disregarding the degree of nesting (it may have any arbitrary set of elementes in between both).\n",
    "    + \"elem1>elem2\" specifically refers to any elem2 children of a direct parent with tag elem1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE:**\n",
    "What does \"div table>img\" select?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style = \"border-radius:10px;border-width:3px;border-color:orange;font-family:Verdana,sans-serif;font-size:16px;\">**BONUS MATERIAL:**\n",
    "\n",
    "<table style =\"border:2px orange solid\">\n",
    "<tr><th style =\"border:3px red solid;color:red;\">FONT</th><th style =\"border:3px red solid;color:red;\">BACKGROUND</th></tr>\n",
    "<tr style =\"border:2px orange solid\">\n",
    "<td style =\"border:2px orange solid;\">\n",
    "<ul style= \"font-family:Courier;\">\n",
    "<li>color</li>\n",
    "<li>font-size:10px,1em,...</li>\n",
    "<li>font-family:Verdana,Garamond,Futura,...</li>\n",
    "</ul>\n",
    "<div style = \"font-size:12px\">font-size size is controlled by pixels (px) or ems (em). One em refers to the normal size the user uses. Two ems refers to twice that size, and so on.\n",
    "\n",
    "Font-families depend on the fonts installed in the computer. However there are some default values: serif, sans-serif, cursive</div>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "<ul style= \"font-family:Courier;\">\n",
    "<li>background-color</li>\n",
    "<li>text-align: left,right,center;</li>\n",
    "</ul>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "**CONTAINER LAYOUT**\n",
    "\n",
    "Any container or element has the following layout:\n",
    "\n",
    "<img src=\"./files/margin_border_padding.png\"/>\n",
    "\n",
    "*T* stands for top, *B* for bottom, *L* and *R* for left and right, respectively. We can modify all the attributes: *margin* (outside the container) and *padding* (inside the container) e.g. *margin:10px* (it will add a margin of 10 pixels to all sides), *padding-top:10px* will just add 10 pixels inside the top side of the container. *Border* can be accessed the same way but also we can add other modifiers such as *border-style:dotted/dashed/solid;*, *\"border-radius:10px/20%;\"*, *\"border-width:5px\"*, *\"border-color:red;\"*. \n",
    "\n",
    "<br>\n",
    "\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE:**\n",
    "Take a look at the following *div* and identify the container related elements:\n",
    "\n",
    "<div style = \"height:200px;width:400px;background-color:#FFCC66;border-width:10px;border-style:solid;border-color:red;padding:10px 30px 5px 100px;color:black;\"> Crux sacra sit mihi lux / Non draco sit mihi dux\n",
    "Vade retro satana / Numquam suade mihi vana\n",
    "Sunt mala quae libas / Ipse venena bibas\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "**CSS POSITIONING**\n",
    "\n",
    "Positioning is one of the toughest parts in CSS styling. For the sake of completeness we will briefly give some hints on how positioning is controlled.\n",
    "\n",
    "The key attributes are *display*, *float*, and *position*. \n",
    "\n",
    "<ul>\n",
    "<li> <strong>Display:</strong></li>\n",
    "<ul>\n",
    "<li>**block:** Makes the element a block box. It does not let anything sit next to it on the page.</li>\n",
    "<li>**inline-block:** Makes the element a block box, but allow other elements to sit next ot it in the same line.</li>\n",
    "<li>**inline:** Makes the element sit on the same line as another element, but without formatting it like a block. It only takes up as much width as it needs (not the whole line).</li>\n",
    "<li>**none:** Makes the element disapear.</li>\n",
    "</ul>\n",
    "<li><strong>Float:</strong></li>\n",
    "<ul>\n",
    "<li>**left:** Floats the element to the left of the window.</li>\n",
    "<li>**right:** Floats the element to the rightmost side of the window.</li>\n",
    "</ul>\n",
    "<li><strong>Position:</strong></li>\n",
    "<ul>\n",
    "<li>**absolute:** The element is positioned relative to its first positioned (not static) ancestor element.</li>\n",
    "<li>**relative:** The element is positioned relative to its normal position, so \"left:20\" adds 20 pixels to the element's LEFT position.</li>\n",
    "<li>**fixed:** Stays even when there is scroll up or down.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "It is worth mentioning the tag *clear:both/left/right* that defines what floats are not allowed, e.g. clear:both will not allow any float to be on the left of right. This is interesting for making some container to be at the bottom of several floats.\n",
    "**PSEUDO-SELECTORS**\n",
    "\n",
    "Pseudo-selectors allows to change aspect according to functional aspects. For example, change color when the mouse is hovering over a link or change the style of a visited link. They are added using colon (selector:pseudo-selector), examples:\n",
    "<ul>\n",
    "<li>a:link: An unvisited link.</li>\n",
    "<li>a:visited: A visited link.</li>\n",
    "<li>a:hover: A link you're hovering your mouse over.</li>\n",
    "</ul>\n",
    "<br>\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**EXERCISE:**\n",
    "Take a look at the file 'stylesheet.css' in our second example and locate the positioning elements.\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "    **Attribute based CSS selectors:**\n",
    "        <ul>\n",
    "        <li> We can select an attribute that has an specific attribute. Syntax is as follows:\n",
    "        <p style = \"font-family:Courier;margin-left:150px;\">\n",
    "            element[attribute = value] { styling_property; }\n",
    "        </p>\n",
    "        e.g. The following code will be applied to all buttons:\n",
    "        <p style = \"font-family:Courier;margin-left:150px;\">\n",
    "            input[type = \"button\"] { font-size:24px; }\n",
    "        </p>\n",
    "        </li>\n",
    "        <li> More complex search patterns can be used using: \n",
    "            <ul> \n",
    "            <li><span style = \"font-family:Courier\">attribute~=value</span> : Finds attributes that contain the whole word value in lists of space separated words</li> \n",
    "            <li><span style = \"font-family:Courier\">attribute|=value</span> : Finds attributes that contain the whole word in a hyphens(dashed) separated list.</li>\n",
    "            <li><span style = \"font-family:Courier\">attribute^=value</span> : Finds attributes that start with the string. It can be part of a larger word. </li> \n",
    "             <li><span style = \"font-family:Courier\">attribute$=value</span> : Finds attributes that end with the string. It can be part of a larger word. </li> \n",
    "             <li><span style = \"font-family:Courier\">attribute\\*=value</span> : Finds attributes that **contain** the string. It can be part of a larger word. </li> \n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>We can chain multiple attribute selectors:\n",
    "        <p style = \"font-family:Courier;margin-left:50px;\">\n",
    "            element[attribute1 = value1][attribute2 = value2]<br> { styling_property; }\n",
    "        </p>\n",
    "        </li>\n",
    "        </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FULL REFERENCE OF CSS SELECTORS:\n",
    "\n",
    "<table style=\"font-family:Courier;font-size:14px;\">\n",
    "  <tbody><tr>\n",
    "    <th style=\"width:20%\">Selector</th>\n",
    "    <th style=\"width:20%\">Example</th>\n",
    "    <th style=\"width:55%\">Example description</th>\n",
    "    <th>CSS</th>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td>.<i>class</i></td>\n",
    "    <td class=\"notranslate\">.intro</td>\n",
    "    <td>Selects all elements with class=\"intro\"</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td>#<i>id</i></td>\n",
    "    <td class=\"notranslate\">#firstname</td>\n",
    "    <td>Selects the element with id=\"firstname\"</td>\n",
    "    <td>1</td>\n",
    "  </tr>  <tr>\n",
    "  <td>\\*</td>\n",
    "  <td class=\"code notranslate\">\\*</td>\n",
    "    <td>Selects all elements</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><i><a href=\"sel_element.asp\">element</a></i></td>\n",
    "    <td class=\"notranslate\">p</td>\n",
    "    <td>Selects all &lt;p&gt; elements</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><i><a href=\"sel_element_comma.asp\">element,element</a></i></td>\n",
    "    <td class=\"notranslate\">div,p</td>\n",
    "    <td>Selects all &lt;div&gt; elements and all &lt;p&gt; elements</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"sel_element_element.asp\"><i>element</i> <i>element</i></a></td>\n",
    "    <td class=\"notranslate\">div p</td>\n",
    "    <td>Selects all &lt;p&gt; elements inside &lt;div&gt; elements</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"sel_element_gt.asp\"><i>element</i>&gt;<i>element</i></a></td>\n",
    "    <td class=\"notranslate\">div&gt;p</td>\n",
    "    <td>Selects all &lt;p&gt; elements where the parent is a &lt;div&gt; element</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"sel_element_pluss.asp\"><i>element</i>+<i>element</i></a></td>\n",
    "    <td class=\"notranslate\">div+p</td>\n",
    "    <td>Selects all &lt;p&gt; elements that are placed immediately after &lt;div&gt; elements</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_gen_sibling.asp\"><i>element1</i>~<i>element2</i></a></td>\n",
    "    <td>p~ul</td>\n",
    "    <td>Selects every &lt;ul&gt; element that are preceded by a &lt;p&gt; element</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attribute.asp\">[<i>attribute</i>]</a></td>\n",
    "    <td class=\"notranslate\">[target]</td>\n",
    "    <td>Selects all elements with a target attribute</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attribute_value.asp\">[<i>attribute</i>=<i>value</i>]</a></td>\n",
    "    <td class=\"notranslate\">[target=_blank]</td>\n",
    "    <td>Selects all elements with target=\"_blank\"</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attribute_value_contains.asp\">[<i>attribute</i>~=<i>value</i>]</a></td>\n",
    "    <td class=\"notranslate\">[title~=flower]</td>\n",
    "    <td>Selects all elements with a title attribute containing the word \"flower\"</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attribute_value_lang.asp\">[<i>attribute</i>|=<i>value</i>]</a></td>\n",
    "    <td class=\"notranslate\">[lang|=en]</td>\n",
    "    <td>Selects all elements with a lang attribute value starting with \"en\"</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attr_begin.asp\">[<i>attribute</i>^=<i>value</i>]</a></td>\n",
    "    <td>a[href^=\"https\"]</td>\n",
    "    <td>Selects every &lt;a&gt; element whose href attribute value begins with \"https\"</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attr_end.asp\">[<i>attribute</i>\\$=<i>value</i>]</a></td>\n",
    "    <td>a[href$=\".pdf\"]</td>\n",
    "    <td>Selects every &lt;a&gt; element whose href attribute value ends with \".pdf\"</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_attr_contain.asp\">[<i>attribute</i>\\*=<i>value</i>]</a></td>\n",
    "    <td>a[href*=\"w3schools\"]</td>\n",
    "    <td>Selects every &lt;a&gt; element whose href attribute value contains the substring \n",
    "\t\"w3schools\"</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_active.asp\">:active</a></td>\n",
    "    <td class=\"notranslate\">a:active</td>\n",
    "    <td>Selects the active link</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_after.asp\">::after</a></td>\n",
    "    <td class=\"notranslate\">p::after</td>\n",
    "    <td>Insert content after every &lt;p&gt; element</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_before.asp\">::before</a></td>\n",
    "    <td class=\"notranslate\">p::before</td>\n",
    "    <td>Insert content before&nbsp; the content of every &lt;p&gt; element</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_checked.asp\">:checked</a></td>\n",
    "    <td>input:checked</td>\n",
    "    <td>Selects every checked &lt;input&gt; element</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_disabled.asp\">:disabled</a></td>\n",
    "    <td>input:disabled</td>\n",
    "    <td>Selects every disabled &lt;input&gt; element</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_empty.asp\">:empty</a></td>\n",
    "    <td>p:empty</td>\n",
    "    <td>Selects every &lt;p&gt; element that has no children (including text nodes)</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_enabled.asp\">:enabled</a></td>\n",
    "    <td>input:enabled</td>\n",
    "    <td>Selects every enabled &lt;input&gt; element</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"sel_firstchild.asp\">:first-child</a></td>\n",
    "    <td class=\"notranslate\">p:first-child</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the first child of its parent</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_firstletter.asp\">::first-letter</a></td>\n",
    "    <td class=\"notranslate\">p::first-letter</td>\n",
    "    <td>Selects the first letter of every &lt;p&gt; element</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_firstline.asp\">::first-line</a></td>\n",
    "    <td class=\"notranslate\">p::first-line</td>\n",
    "    <td>Selects the first line of every &lt;p&gt; element</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_first-of-type.asp\">:first-of-type</a></td>\n",
    "    <td>p:first-of-type</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the first &lt;p&gt; element of its parent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_focus.asp\">:focus</a></td>\n",
    "    <td class=\"notranslate\">input:focus</td>\n",
    "    <td>Selects the input element which has focus</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_hover.asp\">:hover</a></td>\n",
    "    <td class=\"notranslate\">a:hover</td>\n",
    "    <td>Selects links on mouse over</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_in-range.asp\">:in-range</a></td>\n",
    "    <td class=\"notranslate\">input:in-range</td>\n",
    "    <td>Selects input elements with a value within a specified range</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_invalid.asp\">:invalid</a></td>\n",
    "    <td class=\"notranslate\">input:invalid</td>\n",
    "    <td>Selects all input elemets with an invalid value</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_lang.asp\">:lang(<i>language</i>)</a></td>\n",
    "    <td class=\"notranslate\">p:lang(it)</td>\n",
    "    <td>Selects every &lt;p&gt; element with a lang attribute equal to \"it\" \n",
    "\t(Italian)</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_last-child.asp\">:last-child</a></td>\n",
    "    <td>p:last-child</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the last child of its parent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_last-of-type.asp\">:last-of-type</a></td>\n",
    "    <td>p:last-of-type</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the last &lt;p&gt; element of its parent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"sel_link.asp\">:link</a></td>\n",
    "    <td class=\"notranslate\">a:link</td>\n",
    "    <td>Selects all unvisited links</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_not.asp\">:not(<i>selector</i>)</a></td>\n",
    "    <td>:not(p)</td>\n",
    "    <td>Selects every element that is not a &lt;p&gt; element</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_nth-child.asp\">:nth-child(<i>n</i>)</a></td>\n",
    "    <td>p:nth-child(2)</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the second child of its parent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_nth-last-child.asp\">:nth-last-child(<i>n</i>)</a></td>\n",
    "    <td>p:nth-last-child(2)</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the second child of its parent, counting \n",
    "\tfrom the last child</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_nth-last-of-type.asp\">:nth-last-of-type(<i>n</i>)</a></td>\n",
    "    <td>p:nth-last-of-type(2)</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the second &lt;p&gt; element of its parent, counting \n",
    "\tfrom the last child</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_nth-of-type.asp\">:nth-of-type(<i>n</i>)</a></td>\n",
    "    <td>p:nth-of-type(2)</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the second &lt;p&gt; element of its parent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_only-of-type.asp\">:only-of-type</a></td>\n",
    "    <td>p:only-of-type</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the only &lt;p&gt; element of its \n",
    "\tparent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_only-child.asp\">:only-child</a></td>\n",
    "    <td>p:only-child</td>\n",
    "    <td>Selects every &lt;p&gt; element that is the only child of its parent</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_optional.asp\">:optional</a></td>\n",
    "    <td class=\"notranslate\">input:optional</td>\n",
    "    <td>Selects input elements with no \"required\" attribute</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_out-of-range.asp\">:out-of-range</a></td>\n",
    "    <td class=\"notranslate\">input:out-of-range</td>\n",
    "    <td>Selects input elements with a value outside a specified range</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_read-only.asp\">:read-only</a></td>\n",
    "    <td class=\"notranslate\">input:read-only</td>\n",
    "    <td>Selects input elements with the \"readonly\" attribute specified</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_read-write.asp\">:read-write</a></td>\n",
    "    <td class=\"notranslate\">input:read-write</td>\n",
    "    <td>Selects input elements with the \"readonly\" attribute NOT specified</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_required.asp\">:required</a></td>\n",
    "    <td class=\"notranslate\">input:required</td>\n",
    "    <td>Selects input elements with the \"required\" attribute specified</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_root.asp\">:root</a></td>\n",
    "    <td>:root</td>\n",
    "    <td>Selects the document's root element</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_selection.asp\">::selection</a></td>\n",
    "    <td>::selection</td>\n",
    "    <td>Selects the portion of an element that is selected by a user</td>\n",
    "    <td>&nbsp;</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_target.asp\">:target</a></td>\n",
    "    <td>#news:target </td>\n",
    "    <td>Selects the current active #news element (clicked on a URL containing that anchor name)</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_valid.asp\">:valid</a></td>\n",
    "    <td class=\"notranslate\">input:valid</td>\n",
    "    <td>Selects all input elements with a valid value</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "\t<tr>\n",
    "    <td><a href=\"sel_visited.asp\">:visited</a></td>\n",
    "    <td class=\"notranslate\">a:visited</td>\n",
    "    <td>Selects all visited links</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Hands on with CSS selection\n",
    "\n",
    "Different web-focused parsing libraries allow to use CSS selection. In this course we will see a couple of them. The first one is **LXML**. \n",
    "\n",
    "LXML is build upon the C libraries libxml2 and libxslt. These libraries brings standards-compliant XML support as wells as support for (broken) HTML and are very, very fast!\n",
    "\n",
    "LXML allows to use CSS selection. Let us make some drills with lxml.\n",
    "\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**LXML EXERCISES** With the source of python.org\n",
    "<ol>\n",
    "<li>How many paragraphs are on the page?</li>\n",
    "<li>What is the text content of the div wiht the class \"shrubbery\"? What are the links in that same div?</li>\n",
    "<li>What is the text in the code elements?</li>\n",
    "<li><strong>BONUS:</strong> Are there any forms?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "#source = urllib2.urlopen(\"file:///Users/oriol/docencia/DataScience_Postgraduate/datascienceUB_notebooks/scraping/files/example3.html\")\n",
    "source = urlopen(\"http://www.python.org\")\n",
    "from lxml import html\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "tree = html.document_fromstring(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX1\n",
    "len(tree.cssselect('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX2.a\n",
    "[elem.text_content() for elem in tree.cssselect('.main-header')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX2.b\n",
    "for elem in tree.cssselect('div.shrubbery'):\n",
    "    print ([l for l in elem.iterlinks()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX3\n",
    "[elem.text_content() for elem in tree.cssselect('code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX4\n",
    "tree.cssselect('form')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 XPATH as an alternative to CSSSelect\n",
    "\n",
    "XPath is an alternative way of navigating through XML-like documents. It follows a similar structure to file directory navigations. In this sense, we can define an absolut path using /. This means that we have to give the complete path to the element we want to select. For example xpath('/html/body/p') will select all the paragraphs in the body of the html root.\n",
    "\n",
    "If the path starts with // we are not starting at the root but will select an element starting anywhere in the hierarchy. For example  xpath('//a/div') will look for an 'a' followed with a 'div' anywhere in the document. \n",
    "\n",
    "We may also use wildcards suchs as *. For example xpath('//a/div/*') will return all the elements preceeding a/div anywhere in the document. And xpath('/*/*/div') will look for divs at the second level of the hierarchy with respect to the root.\n",
    "\n",
    "If the selection returns more than one element we can choose one using brakets. For example xpath('//a/div[1]') will return the first div element of that set and xpath('//a/div[last()]') the last one.\n",
    "\n",
    "We can toy with attributes using @. In this sense xpath('//@name') returns all attributes called 'name' anywhere in the document, and xpath('//div[@name]') selects from all the divs in the document only those that have an attribute 'name'. Note that it selects the divs, not the attributes. xpath('//div[not(@*)]') will return all the divs without attributes. We can even look for specific values of attributes xpath('//div[@name='chachiname']')\n",
    "\n",
    "There are built-in functions that may help in localizing elements, such as count(),\n",
    "name(), starts-with(), contains(). For example, xpath('//*[contains(name(),'iv')]') will selet all elements anywhere in the document with an name descriptor containing the substring 'iv'; or xpath('//*[count('div')==2]) will return all elements with two div elements as children.\n",
    "\n",
    "We can select elements coming from several paths using | (OR), e.g. xpath('/div/p|/div/a') elements either div/p or div/a.\n",
    "\n",
    "We can refer to the parent, ancestors, child, or descendants in a path, e.g. xpath('//div/div/parent::*') returns the parent nodes that have as children the path div/div.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "**XPATH Exercises**:\n",
    "<ol>\n",
    "<li>Text that are on the lists of the page?</li>\n",
    "<li>All the attributes on the page</li>\n",
    "<li>Is there any link on the page?</li>\n",
    "<li>Can you get the style sheet information?</li>\n",
    "<li>divs that have the class \"container\"</li>\n",
    "<li>what if you remove brackets in the last one?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath('//li/text()')\n",
    "#tree.xpath('//li/a/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath('//@*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree.xpath('//a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath('//style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath('//link/@href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tree.xpath('//link[contains(@href,\"css\")]'):\n",
    "    print (item.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath('//div[@class=\"container\"]') #exact match\n",
    "#tree.xpath('//div[contains(@class,\"container\")]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath('//div/@class=\"container\"') #exact match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 The inexistent data scraping case\n",
    "\n",
    "As a simple exercise try to scrap the numerical value in the text box of the hidden.html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=./files/hidden.html width=700 height=300></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "from urllib.request import urlopen\n",
    "socket = urlopen(\"file:./files/hidden.html\")\n",
    "print (socket.read().decode('latin-1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems and limitations of LXML and basic scraping techniques,\n",
    "\n",
    "     + DOM loaded content. The page finishes loading and it is being acquired when the response is closed. Any further data will be not loaded.\n",
    "     + Really broken HTML/XML\n",
    "     + Proprietary and login required can be difficult depending on the log and flow of the page.\n",
    "     + JS form interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JUST FOR FUN: MARIO MAGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=./files/mario.html width=700 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style = \"border-radius:10px;border-width:3px;border-color:orange;font-family:Verdana,sans-serif;font-size:16px;\">**BONUS MATERIAL:**\n",
    "\n",
    "In order to add a javascript script we simply declare the script file in the head of the html document. For example <br>\n",
    "<span style = \"font-family:Courier;\"> < script type=\"text/javascript\" src=\"script.js\">< /script></span><br>\n",
    "and <br>\n",
    "<span style = \"font-family:Courier;\">< script type='text/javascript' src=\"http://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js\">< /script></span><br>\n",
    "\n",
    "Next, we'll need to start up our jQuery magic using the **\\$(document).ready();** syntax. **\\$()** says, \"hey, jQuery things are about to happen!\". Putting document between the parentheses tells us that we're about to work our magic on the HTML document itself.\n",
    "**.ready();** is a function, or basic action, in jQuery. It says \"hey, I'm going to do stuff as soon as the HTML document is ready!\". Whatever goes in .ready()'s parentheses is the jQuery event that occurs as soon as the HTML document is ready.\n",
    "\n",
    "So,\n",
    "<p style = \"font-family:Courier;\">\n",
    "\\$(document).ready(something);\n",
    "</p>\n",
    "\n",
    "Example:\n",
    "<p style = \"font-family:Courier;\">\n",
    "\\$(document).ready(function(){<br>\n",
    " \\$('div').mouseenter(function(){<br>\n",
    "    \\$('div').fadeTo('fast',1);<br>\n",
    " });   <br>\n",
    " \\$('div').mouseleave(function(){<br>\n",
    "    \\$('div').fadeTo('fast',0.5);<br>\n",
    " });\n",
    "});\n",
    "</p>\n",
    "\n",
    "\n",
    "**Some functions:**\n",
    "<ul>\n",
    "<li>.click()</li>\n",
    "<li>.fadeTo(speed='fast,slow',alpha_value)</li>\n",
    "<li>.fadeOut(speed)</li>\n",
    "<li>.fadeIn(speed)</li>\n",
    "<li>.hide()</li>\n",
    "</ul>\n",
    "\n",
    "**Variables**\n",
    "<p style = \"font-family:Courier\">\n",
    "var lucky = 7;<br>\n",
    "var name = \"\";<br>\n",
    "var \\$p = \\$('p');\n",
    "</p>\n",
    "Note that \\$p is a variable and could be anything, number, etc. In this case we use it to store the JQuery functionality.\n",
    "<p>\n",
    "**JQuery objects are defined by: \\$()**\n",
    "<br>\n",
    "The special tag 'this' e.g. \\$(this), will select the item on which the action is being performed. We can use it to change the behavior of the element. For example\n",
    "<p style = \"font-family:Courier\">\n",
    "\\$(document).ready(function(){\n",
    "$(this).fadeOut('fast');\n",
    "});<br>\n",
    "</p>\n",
    "\n",
    "\n",
    "**Adding elements:**\n",
    "<ul>\n",
    "<li>\\$(where).append(\"stuff\")</li>\n",
    "<li>.prepend()</li>\n",
    "\n",
    "<li>\\$(where).before(\"stuff to append\")</li>\n",
    "<li>.after()</li>\n",
    "\n",
    "<li>.empty()</li>\n",
    "<li>.remove()</li>\n",
    "</ul>\n",
    "A nice trick with .after() is to select something with a variable and move it using .after(). For example:\n",
    "<br>\n",
    "<p style = \"font-family:Courier\">\n",
    "    \\$p = \\$('#one')<br>\n",
    "    \\$('div').after($p)\n",
    "</p>\n",
    "\n",
    "This will take the contents of element with id = \"one\" and move it after the tag \"div\"\n",
    "\n",
    "<br>\n",
    "We can also alter attributes:\n",
    "<ul>\n",
    "<li>.addClass()</li>\n",
    "<li>    .removeClass()</li>\n",
    "<li>    .toggleClass() if the class is present it removes it, otherwise it is added.</li>\n",
    "<li>    .css(style, value) allows to add style CSS commands ex. .css('color','red')</li>\n",
    "</ul>\n",
    "\n",
    "Example:    \n",
    "<p style = \"font-family:Courier\">\n",
    "    \\$(document).ready(function(){<br>\n",
    "    \\$('div').height(200);<br>\n",
    "    \\$('div').width(200);<br>\n",
    "    \\$('div').css('border-radius',10);<br>\n",
    "});\n",
    "</p>\n",
    "\n",
    "Finally, we can alter the content!!!! (scraping here we go!) using **.val()** or **.html()**.\n",
    "Examples:\n",
    "<br>\n",
    "<span style = \"font-family:Courier\">   \\$('div').html(); </span> -> will get the content of the first match, that is the first div.\n",
    "<br><span style = \"font-family:Courier\"> \\$('div').html(\"I love JQuery!\"); </span>-> will set the content of the first match to the value.\n",
    "<br> **.val**  will retrieve the value of forms. For example:\n",
    "<br><span style = \"font-family:Courier\">\\$('input:checkbox:checked').val();</spane> would get the value of the first checked checkbox that jQuery finds. \n",
    "\n",
    "<p>\n",
    "**GENERAL EVENT HANDLERS**\n",
    "The standard notation goes as follows\n",
    "\n",
    "<br><span style = \"font-family:Courier\">\\$(document).on('event', 'selector', function() {\n",
    "Do something!});  </span>\n",
    "<br>\n",
    "A nice example can be checked in jquery_events_example.html,.css,.js\n",
    "</p>  \n",
    "    \n",
    " \n",
    "**SOME JQUERY EVENTS**\n",
    "\n",
    "The general way of handling events is as follows:\n",
    "\n",
    "<p style = \"font-family:Courier\">\n",
    "\\$(document).ready(function() {<br>\n",
    "    \\$('thingToTouch').event(function() {<br>\n",
    "        \\$('thingToAffect').effect();<br>\n",
    "    });<br>\n",
    "});\n",
    "</p>\n",
    "\n",
    "Example of events:\n",
    "<ul>\n",
    "<li>.dblclick()</li>\n",
    "<li>.hover()</li>\n",
    "<li>.focus()</li>\n",
    "<li>.keydown()</li>\n",
    "</ul>\n",
    "Example:\n",
    "<p style = \"font-family:Courier\">\n",
    "\\$('div').hover(<br>\n",
    "   function(){<br>\n",
    "      \\$(this).addClass('highlight');<br>\n",
    "   },<br>\n",
    "   function(){<br>\n",
    "      \\$(this).removeClass('highlight');<br>\n",
    "   }<br>\n",
    ");<br>\n",
    "</p>\n",
    "    \n",
    "And a final cool **effect**:\n",
    "<br>\n",
    ".draggable()\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Advanced scraping using automation tools\n",
    "\n",
    "We see the data in our web browser but the data is not directly found in the html. However \"Data is out there\". This is due to the fact that it has been dinamically generated with a function call. Thus, we see that we have two versions of the web page. The first contains static data and function calls, the second contains static data after the interpretation of the function calls. The question now is how we can access this post interpretation data. There are many different ways. One way could be opting for running our own interpreter such as node.js. Another way is to take advantage of the browser interpretation capabilities and run it as an interpreter.\n",
    "\n",
    "Automation tools such as mechanize or selenium are suites with the goal of testing web interfaces automatically from scripts. They allow to start a browser and interact with the web page in the same way a human user would do. We can use these tools for our scraping purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cepstral demo and our new goal.\n",
    "<small>An updated version of the case study of Asheesh Laroia (PaulProtheus at Github)</small>\n",
    "\n",
    "Our new goal is to deal with dynamically generated data. Our goal is to be able to perform a web scraping as the following case. Cepstral is a text-to-speech provider. Let us check the web page.\n",
    "\n",
    "We will need to download geckodriver for Firefox to work \n",
    "https://github.com/mozilla/geckodriver/releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"http://cepstral.com\" width=700 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to retrieve the audio file that has been played using web scraping techniques. Let us check how can we do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export PATH=$PATH:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "browser.get('http://seleniumhq.org/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEPSTRAL DEMO\n",
    "%reset -f\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "url = 'http://www.cepstral.com/en/demos' #Poseu el nom de la pàgina web\n",
    "browser = webdriver.Firefox() #Obrir un navegador Chrome\n",
    "browser.get(url)\n",
    "element = browser.find_element_by_css_selector(\"#demo_text\")\n",
    "element.clear()\n",
    "s='Hi this is a very boring class! Wow, so awesome!'\n",
    "element.send_keys(s)\n",
    "browser.find_element_by_css_selector('#demo_submit').click()\n",
    "\n",
    "browser.implicitly_wait(30)\n",
    "browser.find_element_by_css_selector('audio')\n",
    "html=browser.page_source\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data is in\n",
    "'.mp3' in html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate it\n",
    "html.find('.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=html.split('\"')\n",
    "for chunk in chunks:\n",
    "    if '.mp3' in chunk:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "furl=urllib.parse.urljoin(url,chunk)\n",
    "print (furl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "player = \"/Applications/VLC.app/Contents/MacOS/VLC \" \n",
    "\n",
    "##Replace with media player with your own player \n",
    "os.system(player+furl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Starting with Selenium \n",
    "\n",
    "+ Requirements\n",
    "        ''pip install selenium''\n",
    "        \n",
    "If you use Firefox you do not need anything else. Check the following code and it should work fine.\n",
    "\n",
    "We will need to download geckodriver for Firefox to work \n",
    "https://github.com/mozilla/geckodriver/releases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export PATH=$PATH:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use Chrome you need the Chrome webdriver interface 'chromedriver'. \n",
    "\n",
    "+ Download 'chromedriver' 2.10 at the time of this notebook.\n",
    "+ You need to add the chromedriver path into the executable path. (We will do it directly on python)\n",
    "\n",
    "Check the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import os \n",
    "os.environ[\"PATH\"] = '$PATH:.' \n",
    "browser = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">**Basic manipulation in Selenium:**\n",
    "<p>\n",
    "A webdriver instance allows to manipulate the web session, control cookies, retrieve the html code or find elements in the source code.\n",
    "</p>\n",
    "Given a webdriver instance (e.g.<span style = \"font-family:Courier;\">\n",
    "            browser = webdriver.Firefox()</span>) the most relevant methods\n",
    "\n",
    "<ul>\n",
    "<li>**Open URL:**  .get(url) (e.g.\n",
    "<span style = \"font-family:Courier;\"> browser.get(url)</span>)</li>\n",
    "<li>**Selection: ** .find_element(s)... [element will return the first, elements the complete list]\n",
    "<ul>\n",
    "<li>..._by_link_text('foo') - find the link with text foo</li>\n",
    "<li>..._by_partial_link_text() - similar to contains ...</li>\n",
    "<li>..._by_css_selector()</li>\n",
    "<li>..._by_tag_name()</li>\n",
    "<li>..._by_xpath()</li>\n",
    "<li>..._by_class_name()</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>**Retrieve source: ** .page_source</li>\n",
    "  \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"background-color:lightyellow;border-radius:10px;border-width:3px;border-color:darkorange;font-family:Verdana,sans-serif;font-size:16px;color:brown\">**Other web driver utilities:**\n",
    "<ul>\n",
    "<li>browser.execute_script('window.close()') - execute any javascript on a load page</li>\n",
    "<li>brosers.save_screenshot('foo.png')</li>\n",
    "<li>browser.switch_to_alert(): handle pop-ups automatically</li>\n",
    "<li>browser.forward() / browser.back(): navigation</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**Exercise: Simple retrieval of a page source with AJAX.**\n",
    "The prices of a search flight on google is a dinamically generated page. Let us suppose we want to find the cheapest price for a certain flight. We may access the google flights by means of the API.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os \n",
    "os.environ[\"PATH\"] = '$PATH:.' \n",
    "url = 'https://www.google.es/flights/#search;f=BCN;t=MAD;d=2017-11-12;r=2017-11-16' #Poseu el nom de la pàgina web\n",
    "browser = webdriver.Firefox() \n",
    "browser.get(url)\n",
    "time.sleep(3) #Wait for the page to load\n",
    "browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\") #Scroll down\n",
    "\n",
    "html=browser.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use basic string manipulation to retrieve the price.\n",
    "import re\n",
    "for m in re.finditer(r\"€\", html):\n",
    "    print ('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))\n",
    "    print (html[m.start()-10:m.start()+1])\n",
    "\n",
    "\n",
    "#euro = html.find_all('€')\n",
    "#html[euro-5:euro-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">**Element manipulation in Selenium:**\n",
    "<p>\n",
    "Consider the result of a selection, e.g. \n",
    "\n",
    "<span style = \"font-family:Courier;\">element = browser.find_element_by_css_selector('div')</span>\n",
    "\n",
    "We can do several things on it.\n",
    "<ul>\n",
    "<li>element**.click()** - click on a selected element</li>\n",
    "<li>Element properties:\n",
    "<ul>\n",
    "<li>element**.location**: x, y location</li>\n",
    "<li>element**.parent**: parent element</li>\n",
    "<li>element**.tag_name**: The tag of the element</li>\n",
    "<li>element**.text**: text of the element and childs</li>\n",
    "</ul>\n",
    "</li>\n",
    "   \n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "**A more elaborate exercise:** Go to Amazon, look for the film \"Ip Man\". Retrieve the list of all movies bought by customers who also bought \"Ip Man\". With this list go to Internet Movie Data Base and sort the list according to the score of the movie.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">**Form input with Selenium:**\n",
    "<ul>\n",
    "<li> element**.send_keys()** - Keys, commands, arrows, etc </li>\n",
    "<li> element**.clear()** - clear the element</li>\n",
    "</ul>\n",
    "<p>\n",
    "\n",
    "**Example.**\n",
    "\n",
    "<p style=\"font-family:Courier;\">\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "<br>input.send_keys('Ip Man',Keys.RETURN)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">**Scrolling and moving:**\n",
    "Moving around the page is tricky, be prepared for displaying a little patience.\n",
    "\n",
    "ActionChains provide a way of stringing together one or more actions and then implementing them.\n",
    "<ul>\n",
    "<li>move_by_offset(x,y)</li>\n",
    "<li>move_to_element() - for highlighting, hovering, rollover, etc.</li>\n",
    "<li>move_to_elemnte_by_offset(elem, x, y)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\"> **Wait**\n",
    "\n",
    "We can distinguish two types of waiting strategies, namely, implicit and explicit waits.\n",
    "\n",
    "*Implicit waits* set up a timeout that will last for the full life of the web driver. On the other hand, *explicit waits* tell the driver to poll the DOM until some condition is met, e.g. a certain element has finished loading on the page. \n",
    "\n",
    "Example:\n",
    "<p style=\"font-family:Courier;\">\n",
    "try: <br>\n",
    "movie_info = webdriverwait(browser,10).until(EC.element_to_be_clickable((By.ID,'BotMovie')))<br>\n",
    "title = movie_info.find_element_by_class_name('title').text<br>\n",
    "link = movie_info.find_element_by_class_name('mdpLink').get_attribute('href')<br>\n",
    "except:<br>\n",
    " print 'taking too long!!'<br>\n",
    " </p>\n",
    " \n",
    "*EC* stands for Expected Condition and are the basis of explicit waits (see http://selenium-python.readthedocs.org for more information)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\"> **Wrap-up**\n",
    "<ul>\n",
    "<li>We understood how data is usually stored in the web site and how to access it using different kinds of accessors, namely API and direct selectors.</li>\n",
    "<li>We have seen how to capture different kinds of data types(text, audio and pictures).</li>\n",
    "<li>We are now familiar with JSON data and basic No-SQL databases.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
